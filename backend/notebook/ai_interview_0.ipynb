{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LJRah8PT9_ux"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "!pip install litellm==1.61.0\n",
        "!pip install coqui-tts\n",
        "!pip install -q numpy==1.24.3 scipy==1.10.1 torch==2.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPRKwTzVIEFq",
        "outputId": "311f9736-b36e-4a27-84a0-2cd2c05190a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pypdf2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf2\n",
            "Successfully installed pypdf2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qqpi15cL-CtP"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from litellm import completion\n",
        "import os\n",
        "import PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNRamVc0-eXG"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76zDvRUh7geP"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.13.3)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/Users/hardiksehgal/Desktop/coding/shivam-ai/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def generate_interview_questions(job_description, resume_text):\n",
        "  prompt = f\"\"\"\n",
        "  Given the following job description and resume text, generate 2 insightful interview questions that will help assess the candidate's suitability for the role.\n",
        "  The questions should be relevant to both the job description and the candidate's background as presented in the resume.\n",
        "\n",
        "  Job Description:\n",
        "  {job_description}\n",
        "\n",
        "  Resume Text:\n",
        "  {resume_text}\n",
        "\n",
        "  Generate questions that explore:\n",
        "  1. How their past experience aligns with the job requirements.\n",
        "  2. Their skills and knowledge in key areas mentioned in the job description.\n",
        "\n",
        "  Generate the questions directly, without any introductory or concluding remarks.\n",
        "  \"\"\"\n",
        "\n",
        "  response = completion(\n",
        "    model=\"gemini/gemini-2.5-flash-preview-04-17\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    temperature=0.7,\n",
        "    response_format={\"type\": \"text\"},\n",
        "  )\n",
        "  return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "SZC1-E2EA6ZR"
      },
      "outputs": [],
      "source": [
        "#@title jd text\n",
        "jd = \"\"\"\n",
        "Job Title: AI/ML Engineer Intern\n",
        "\n",
        "Location: Bengaluru, India\n",
        "\n",
        "Duartion : 6 Months\n",
        "\n",
        "Company Overview: IAI Solution is at the forefront of artificial intelligence and machine learning innovation, driving breakthroughs that impact industries worldwide. We are seeking an experienced AI/ML Engineer intern who is deeply knowledgeable in AI and machine learning techniques, and who thrives in a fast-paced, research-driven environment. If you are passionate about AI, have hands-on experience with model fine-tuning and prompt engineering, and want to be part of a team pushing the boundaries of technology, we would love to hear from you.\n",
        "\n",
        "Position Summary: We are looking for an AI/ML Engineer intern with a strong background in Python, Django, and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, model fine-tuning, and using the HuggingFace libraries. Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications.\n",
        "\n",
        "Key Responsibilities:\n",
        "\n",
        "Develop, fine-tune, and deploy machine learning models using Python and Django frameworks.\n",
        "Apply prompt engineering techniques to optimize model outputs and improve accuracy.\n",
        "Utilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models.\n",
        "Work on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently.\n",
        "Collaborate with research teams to translate cutting-edge AI research into scalable solutions.\n",
        "Implement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions.\n",
        "Stay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects.\n",
        "Document and share findings, best practices, and solutions across the engineering team.\n",
        "Qualifications:\n",
        "\n",
        "Strong proficiency in Python and Django.\n",
        "Experience in prompt engineering and fine-tuning AI models.\n",
        "Extensive experience with HuggingFace libraries and similar AI/ML tools.\n",
        "Hands-on experience with cloud platforms such as AWS SageMaker for training and deploying models.\n",
        "Background in AI/ML research, with a preference for candidates from research institutes.\n",
        "Demonstrated experience in training and deploying machine learning models in real-world applications.\n",
        "Solid understanding of object-oriented programming and problem-solving skills.\n",
        "Strong analytical skills and the ability to work independently or in a team environment.\n",
        "Excellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders.\n",
        "Preferred Qualifications:\n",
        "\n",
        "Previous experience in academic or industrial research, with published work in AI/ML.\n",
        "Proven track record of successful AI model deployments and optimizations.\n",
        "Perks & Benefits:\n",
        "\n",
        "Work on groundbreaking AI/ML projects in a collaborative and innovative environment.\n",
        "Access to state-of-the-art tools and cloud platforms.\n",
        "Opportunities for professional development and continuous learning.\n",
        "Comprehensive health and wellness benefits.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF9sxYHqKTk8"
      },
      "outputs": [],
      "source": [
        "#@title pdf to txt fn\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            for page_num in range(len(reader.pages)):\n",
        "                page = reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from {pdf_path}: {e}\")\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyasQIKGKdWN",
        "outputId": "75a9db3f-18ba-4e34-dd83-ef58eaae017b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['.config', 'Mohit Sharma_AIML Engineer.pdf', 'Saniya_AIML INTERN.pdf', 'gaurav choudhary_aiml intern.pdf', 'BALUSA GNANESH_AIML Intern.pdf', 'sample_data']\n",
            "['Mohit Sharma_AIML Engineer.pdf', 'Saniya_AIML INTERN.pdf', 'gaurav choudhary_aiml intern.pdf', 'BALUSA GNANESH_AIML Intern.pdf']\n"
          ]
        }
      ],
      "source": [
        "pdf_directory = '/content/'\n",
        "\n",
        "# Get a list of all files in the directory\n",
        "all_files = os.listdir(pdf_directory)\n",
        "print(all_files)\n",
        "# Filter for PDF files\n",
        "pdf_files = [f for f in all_files if f.endswith('.pdf')]\n",
        "print(pdf_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQzL9xxdMb4r",
        "outputId": "ed5e4837-238e-4ec6-eafa-310c940ecb0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mohit Sharma_AIML Engineer.pdf\n",
            "Extracted text from PDF. Generating interview questions...\n",
            "1.  Your AARIA project involves developing a research agent with a RAG pipeline and multi-agent architecture. How does the experience gained in building this system, particularly in integrating different components and optimizing information retrieval, align with the job requirement of applying prompt engineering techniques and utilizing advanced AI tools?\n",
            "\n",
            "2.  The job description mentions proficiency in Python, Django, and experience with HuggingFace libraries and cloud platforms like AWS SageMaker for training and deploying models. Could you elaborate on your experience level with each of these specific requirements? For areas where your direct experience might be limited, how would you leverage your existing technical skills (e.g., PyTorch, Python) to quickly get up to speed?\n",
            "\n",
            "3.  You've worked on projects like Historical Manuscript Restoration and Supervised Fraud Detection, involving model training and evaluation. Can you walk us through your process for fine-tuning a model for a specific task, and discuss any experience you have with deploying models, including challenges faced in translating research or project work into a deployable solution?\n",
            "\n",
            "4.  Your M.Tech in AI and projects like AARIA indicate a strong interest in AI research, which is preferred for this role. How do you approach staying updated with the latest advancements in the field, and how would you leverage your research background to contribute to translating cutting-edge AI concepts into practical, scalable solutions within our team?\n",
            "------------------------------\n",
            "Saniya_AIML INTERN.pdf\n",
            "Extracted text from PDF. Generating interview questions...\n",
            "1.  The job requires experience with HuggingFace libraries for model fine-tuning and deploying models on cloud platforms like AWS SageMaker. Your resume highlights projects using ML frameworks and you are Google Cloud certified. Can you describe your most significant experience fine-tuning a pre-trained model and deploying it for a real-world application, detailing the tools and platforms you used and the challenges you faced?\n",
            "2.  Your projects like the Semantic Search Engine and Anuvadak AI Assistant involve NLP and interacting with models. Can you discuss your experience with prompt engineering or optimizing model outputs for specific tasks in any of your projects or internships? How did you iterate on prompts or inputs to improve performance?\n",
            "3.  Your resume mentions a research article publication focusing on real-world applications and emerging technologies, and the job emphasizes a research-driven environment. Can you elaborate on the research you conducted or contributed to, and how your findings could potentially be translated into a practical, deployable AI solution?\n",
            "4.  In developing a project like the Anuvadak AI Assistant or the Smart Green Light system, you likely encountered significant technical challenges (e.g., real-time accuracy, performance optimization). Describe one such challenge and how you approached solving it, including any object-oriented design principles or problem-solving strategies you employed.\n",
            "------------------------------\n",
            "gaurav choudhary_aiml intern.pdf\n",
            "Extracted text from PDF. Generating interview questions...\n",
            "1.  Your resume highlights significant experience with Python and ML frameworks like HuggingFace, and projects involving LLMs and RAG systems. The job requires proficiency in Python, Django, and OOP, and experience in prompt engineering. Can you describe your experience with Django, and how you apply object-oriented principles when developing your ML solutions, perhaps referencing one of your projects like the one at IO Corp or Akinator?\n",
            "2.  You mentioned developing a lightweight LLM and integrating RAG for chatbots in your IO Corp internship, and also used RAG with BERT in your Akinator project. Prompt engineering is a key part of optimizing such systems. Can you walk me through your process or specific techniques you used for prompt engineering to improve model outputs and relevance in these projects?\n",
            "3.  Your IO Corp experience involved deploying models on AWS with MLOps pipelines for scalable retraining. The job specifically mentions AWS SageMaker or equivalent platforms for training and deployment. Can you describe your experience using cloud platforms for *training* and deploying ML models at scale, including any challenges you faced and how you addressed them, perhaps comparing approaches if you've used more than one platform?\n",
            "4.  You have a strong research background, demonstrated by your work at BARC, and also significant experience deploying models in real-world applications across various projects. How do you approach translating research concepts or models into practical, scalable solutions ready for deployment? Can you give an example from your experience where you adapted a research idea for a real-world application?\n",
            "5.  In your IO Corp role, you optimized a lightweight LLM for inference speed and memory footprint, aiming for edge deployments. Real-world deployment often requires significant optimization. Can you elaborate on the specific techniques you used to achieve these optimizations (e.g., quantization, pruning, specific architectures, etc.) and how you balanced performance with model size/speed constraints for edge scenarios?\n",
            "------------------------------\n",
            "BALUSA GNANESH_AIML Intern.pdf\n",
            "Extracted text from PDF. Generating interview questions...\n",
            "1.  Your resume mentions experience with Python, FastAPI, and React.js for web application development, and the job description requires proficiency in Python and Django for developing and deploying ML models. Can you describe your experience with Django or other web frameworks specifically for deploying machine learning models, and explain how you would approach integrating an ML model into a web application?\n",
            "2.  The job description emphasizes experience with prompt engineering and fine-tuning AI models, and your projects involve working with LLMs and ML classifiers. Could you elaborate on your practical experience with model fine-tuning techniques and how you've applied prompt engineering to optimize model outputs or evaluate behavior in projects like your LLM Test Automation Suite or Speech Emotion Recognition system?\n",
            "3.  You have demonstrated experience with AWS, including cloud migration and developing a CLI tool for AWS S3, and are an AWS Certified Cloud Practitioner. The role requires experience with AWS SageMaker or similar platforms for training and deploying models. Can you describe your process or workflow for training and deploying an AI model on a cloud platform, and provide an example of a model you've deployed to the cloud, even if not specifically using SageMaker?\n",
            "4.  Your background includes research experience at Tihan IIT Hyderabad and research projects like the Speech Emotion Recognition system, which resulted in publications. This role is in a fast-paced, research-driven environment focused on translating research into scalable solutions. How do you approach staying updated with the latest AI/ML research and integrating new techniques into practical, deployable applications?\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "resumes_data = []\n",
        "for pdf_file in pdf_files:\n",
        "  print(pdf_file)\n",
        "  pdf_path = os.path.join(pdf_directory, pdf_file)\n",
        "  resume_text = extract_text_from_pdf(pdf_path)\n",
        "  if resume_text:\n",
        "    print(\"Extracted text from PDF. Generating interview questions...\")\n",
        "    questions = generate_interview_questions(jd, resume_text)\n",
        "    print(questions)\n",
        "    print(\"-\"*30)\n",
        "    resumes_data.append({\n",
        "        'jd_txt': jd,\n",
        "        'filename': pdf_file,\n",
        "        'resume_txt': resume_text,\n",
        "        'generated_questions': questions\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVP1ZTzTKqsI",
        "outputId": "386e97f4-5d04-45c1-fb54-c324a636fd9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'jd_txt': '\\nJob Title: AI/ML Engineer Intern\\n\\nLocation: Bengaluru, India\\n\\nDuartion : 6 Months\\n\\nCompany Overview: IAI Solution is at the forefront of artificial intelligence and machine learning innovation, driving breakthroughs that impact industries worldwide. We are seeking an experienced AI/ML Engineer intern who is deeply knowledgeable in AI and machine learning techniques, and who thrives in a fast-paced, research-driven environment. If you are passionate about AI, have hands-on experience with model fine-tuning and prompt engineering, and want to be part of a team pushing the boundaries of technology, we would love to hear from you.\\n\\nPosition Summary: We are looking for an AI/ML Engineer intern with a strong background in Python, Django, and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, model fine-tuning, and using the HuggingFace libraries. Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications.\\n\\nKey Responsibilities:\\n\\nDevelop, fine-tune, and deploy machine learning models using Python and Django frameworks.\\nApply prompt engineering techniques to optimize model outputs and improve accuracy.\\nUtilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models.\\nWork on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently.\\nCollaborate with research teams to translate cutting-edge AI research into scalable solutions.\\nImplement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions.\\nStay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects.\\nDocument and share findings, best practices, and solutions across the engineering team.\\nQualifications:\\n\\nStrong proficiency in Python and Django.\\nExperience in prompt engineering and fine-tuning AI models.\\nExtensive experience with HuggingFace libraries and similar AI/ML tools.\\nHands-on experience with cloud platforms such as AWS SageMaker for training and deploying models.\\nBackground in AI/ML research, with a preference for candidates from research institutes.\\nDemonstrated experience in training and deploying machine learning models in real-world applications.\\nSolid understanding of object-oriented programming and problem-solving skills.\\nStrong analytical skills and the ability to work independently or in a team environment.\\nExcellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders.\\nPreferred Qualifications:\\n\\nPrevious experience in academic or industrial research, with published work in AI/ML.\\nProven track record of successful AI model deployments and optimizations.\\nPerks & Benefits:\\n\\nWork on groundbreaking AI/ML projects in a collaborative and innovative environment.\\nAccess to state-of-the-art tools and cloud platforms.\\nOpportunities for professional development and continuous learning.\\nComprehensive health and wellness benefits.\\n\\n', 'filename': 'Mohit Sharma_AIML Engineer.pdf', 'resume_txt': 'Mohit Sharma +91-8504022793\\nRoll No.:M23CSA015 m4mohit21@gmail.com\\nArtificial Intelligence m23csa015@iitj.ac.in\\nComputer Science and Engineering github.com/m4mohit21\\nIndian Institute Of Technology, Jodhpur linkedin.com/in/m4mohitsharma\\nEducation\\nDegree/Certificate Institute/Board CGPA/Percentage Year\\nM.Tech. (AI) Indian Institute of Technology, Jodhpur 7.55 2023-Present\\nB.Tech. (ME) MNIT JAIPUR 8.30 2015-2019\\nSenior Secondary RBSE Board 84.40% 2014\\nSecondary RBSE Board 81.50% 2012\\nExperience\\n•Sadabahar Nidhi Limited June 2021 - June 2023\\nFinancial Data Analyst Intern Bundi, Rajasthan\\n–Entered and managed data for Recurring Deposits (RD) and Fixed Deposits (FD), ensuring accuracy and consistency in\\nfinancial records.\\n–Analyzeddepositorbehaviortoassessfinancialreliability,identifyingindividualswhomaderegulardepositsanddemonstrated\\nresponsibility for loan eligibility.\\n•J.K.Lakshmi Cement July 2019 - Jan. 2020\\nGraduate Engineer Trainee Jaykaypuram\\n–Contributed to the girth gear replacement project and was key in managing a critical 21-day plant shutdown, applying\\nmechanical knowledge to ensure timely completion and efficiency.\\n–Optimized inventory management and workflows by implementing 5S practices in storeroom operations. Monitored machine\\nperformance, conducted root cause analysis, and supported strategic project planning.\\nProjects\\n•Historical Manuscript Restoration\\nVision Transformer-Based Restoration of Old Manuscripts. Github\\n–Trained the T2T-ViT model on H-DIBCO and IGNCA datasets, applying data augmentation to expand the training set to\\n208 images, enabling robust noise reduction and text feature enhancement.\\n–Achieved Precision (96.84%), Recall (86.46%), F1 Score (90.95%), and PSNR (16.64), showcasing significant improvement\\nin readability anddocument clarity.\\n–Tools & technologies used : Python, PyTorch, NumPy, Jupyter Notebook, H-DIBCO/IGNCA datasets.\\n•Supervised Fraud Detection in Insurance Using Social Network Analytics\\nLeveraged social network analytics to improve fraud detection in insurance. Github\\n–Created a random dataset with party and claim associations constraints. Enhanced classification by incorporating network\\nscore-based features , achieving promising results despite limited intrinsic features.\\n–Highlighted potential for integrating social network-based features withintrinsic data for enhanced fraud detection.\\n–Tools:Python, Numpy, Jupyter Notebook, Networkx, Scikit-learn\\n•AARIA: Autonomous Agentic Research and Information Assistant\\nResearch Agent Development with RAG Pipeline, LangGraph and CrewAI Github\\n–Developed a Research Agent with a RAG pipeline andLangGraph for dynamic search, analysis, and summarization, opti-\\nmizing decision-making with graph-based task management.\\n–Integrated Redis, Cohere API, and DuckDuckGo API with tools for academic and web data retrieval.\\n–Implemented a multi-agent architecture withCrewAI for task delegation, incorporating dynamic query generation, selfim-\\nprovement via critique, and efficient feedback handling to enhance scalability and adaptability in research workflows.\\n–Tools:LangGraph, CrewAI, Redis, Cohere API, DuckDuckGo API, Python\\nKey Courses Taken\\n–Deep Learning, Computer Vision, Machine Learning, Social Network Analysis, Ml and Dl Ops, Start a New Venture,\\nAutonomous System, VANET, Digital Image Analysis\\nTechnical Skills\\n–Programming: Python, C, SQL\\n–Tools & OS: Jupyter Notebook, Google Colab, Github, Linux, WandB\\n–Libraries/Frameworks: Pandas, Numpy, Scikit-Learn, Pytorch, Opencv, NetworkX\\nPositions of Responsibility\\n–Teaching Assistant: DLOps, Machine Learning, Human-Machine Interaction, ICS Aug 2023 - Present\\nAchievements\\n–Gate 2023 Qualified Secured 524 gate score in Mechanical Engineering. 2023\\n–HPCL Interview Qualified for HPCL written exam and group task also. 2023\\n–MHRD Scholarship Received State Government Merit Scholarship for Under Graduate 2015-2019', 'generated_questions': \"1.  Your AARIA project involves developing a research agent with a RAG pipeline and multi-agent architecture. How does the experience gained in building this system, particularly in integrating different components and optimizing information retrieval, align with the job requirement of applying prompt engineering techniques and utilizing advanced AI tools?\\n\\n2.  The job description mentions proficiency in Python, Django, and experience with HuggingFace libraries and cloud platforms like AWS SageMaker for training and deploying models. Could you elaborate on your experience level with each of these specific requirements? For areas where your direct experience might be limited, how would you leverage your existing technical skills (e.g., PyTorch, Python) to quickly get up to speed?\\n\\n3.  You've worked on projects like Historical Manuscript Restoration and Supervised Fraud Detection, involving model training and evaluation. Can you walk us through your process for fine-tuning a model for a specific task, and discuss any experience you have with deploying models, including challenges faced in translating research or project work into a deployable solution?\\n\\n4.  Your M.Tech in AI and projects like AARIA indicate a strong interest in AI research, which is preferred for this role. How do you approach staying updated with the latest advancements in the field, and how would you leverage your research background to contribute to translating cutting-edge AI concepts into practical, scalable solutions within our team?\"}, {'jd_txt': '\\nJob Title: AI/ML Engineer Intern\\n\\nLocation: Bengaluru, India\\n\\nDuartion : 6 Months\\n\\nCompany Overview: IAI Solution is at the forefront of artificial intelligence and machine learning innovation, driving breakthroughs that impact industries worldwide. We are seeking an experienced AI/ML Engineer intern who is deeply knowledgeable in AI and machine learning techniques, and who thrives in a fast-paced, research-driven environment. If you are passionate about AI, have hands-on experience with model fine-tuning and prompt engineering, and want to be part of a team pushing the boundaries of technology, we would love to hear from you.\\n\\nPosition Summary: We are looking for an AI/ML Engineer intern with a strong background in Python, Django, and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, model fine-tuning, and using the HuggingFace libraries. Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications.\\n\\nKey Responsibilities:\\n\\nDevelop, fine-tune, and deploy machine learning models using Python and Django frameworks.\\nApply prompt engineering techniques to optimize model outputs and improve accuracy.\\nUtilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models.\\nWork on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently.\\nCollaborate with research teams to translate cutting-edge AI research into scalable solutions.\\nImplement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions.\\nStay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects.\\nDocument and share findings, best practices, and solutions across the engineering team.\\nQualifications:\\n\\nStrong proficiency in Python and Django.\\nExperience in prompt engineering and fine-tuning AI models.\\nExtensive experience with HuggingFace libraries and similar AI/ML tools.\\nHands-on experience with cloud platforms such as AWS SageMaker for training and deploying models.\\nBackground in AI/ML research, with a preference for candidates from research institutes.\\nDemonstrated experience in training and deploying machine learning models in real-world applications.\\nSolid understanding of object-oriented programming and problem-solving skills.\\nStrong analytical skills and the ability to work independently or in a team environment.\\nExcellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders.\\nPreferred Qualifications:\\n\\nPrevious experience in academic or industrial research, with published work in AI/ML.\\nProven track record of successful AI model deployments and optimizations.\\nPerks & Benefits:\\n\\nWork on groundbreaking AI/ML projects in a collaborative and innovative environment.\\nAccess to state-of-the-art tools and cloud platforms.\\nOpportunities for professional development and continuous learning.\\nComprehensive health and wellness benefits.\\n\\n', 'filename': 'Saniya_AIML INTERN.pdf', 'resume_txt': 'Saniya Ladanavar\\n9845967062 |saniyaladanavar123@gmail.com |linkedin |Github\\nEducation\\nVisvesvaraya Technological University Belagavi,Karnataka\\nB.Tech in Computer Science and Business Systems(8.9/10) Dec 2021 - Present\\nRaja Lakhamagouda Science Institute Belagavi,Karnataka\\nClass 12 Science ,(91.16%) June 2020 - July 2021\\nBensons English Medium High School Belagavi,Karnataka\\nHigh School Class 10 ,(90.56%) June 2018 - April 2019\\nExperience\\nResearch Article Publication Aug 2024\\nEuropean Alliance of Innovation Belgaum\\n•The paper highlights practical approaches and advancements contributing to real-world applications and emerging\\ntechnologies.\\nAI Data Intern Sep 2024 – Oct 2024\\nSkypoint.ai On-site , Bengaluru\\n∗Collected, cleaned, and organized datasets to enhance machine learning accuracy and model performance\\nwith fine tuned data pipelines and worked with cross-functional teams to deploy AI solutions while\\nmaintaining comprehensive documentation and presenting insights to US team.\\nSDE Intern Oct 2023 – Nov 2023\\nCNC ITISMU On-site , Belagavi\\n∗Configured and optimized VLANs for secure, segmented networks, enhancing performance and reducing\\ntraffic bottlenecks and Collaborated with IT teams to troubleshoot network issues, ensuring seamless lab\\noperations and efficient VLAN management.\\nProjects\\nAI-Driven Semantic Search Engine |AI/ML link\\n∗Built a semantic search engine using BERT and Elasticsearch , Integrated NLP models to enhance query\\nintent detection by 30% and deliver precise, context-aware results and Optimized indexing, query tuning, and\\nsearch relevance for large datasets, ensuring high-performance search operations.\\nAnuvadak - AI Assistant |Machine Learning, Python link\\n∗Engineered an AI-powered assistant that converts sign language into text with 80% real-time accuracy ,\\nenhancing accessibility and Integrated machine learning, computer vision, and NLP for seamless gesture\\nrecognition and optimized , system performance for inclusive communication solutions.\\nSmart Green Light |AI/ML link\\n∗Developed an AI-powered traffic management system to optimize signal timings based on real-time traffic flow,\\nreducing congestion and improving efficiency through data-driven decision-making.\\nAWARDS AND ACHIEVEMENTS\\nGoogle Cloud Certified : link - Data, ML, AI, Generative AI, Networking secuirity and Cloud Computing Google\\nDevelopers Group (GDG) Lead VTU : Fostering a vibrant tech community through events and projects\\nStartup Mahakumbh - India’s largest startup event : Represented my univeristy (VTU) solely from my\\nBatch’25\\nAcademic excellence: : Best Student of the year (All Rounder) and awards in leadership, debate, public speaking.\\nConference Paper Presentation : 1st International Conference of Advanced Computing Technologies 2024.Skills\\nLanguages/Skills : C++, Python, Machine Learning, Web Development, Blockchain, Mysql, Powerbi, Excel\\nFrameworks : Django, Reactjs, Nodejs, streamlit, Tensorflow, Keras, scikit-learn, Mat-plotlib, OpenCV\\nDeveloper Tools and Platforms : VS Code, Jupyter Notebook, Notepad++, Linux, Unix\\nInterpersonal skills : Public Speaking, Leadership, Effective Communicator, Team Collaboration, Presentation\\nPosition of Responsibility\\nLead at Technical and Personality Development Clubs , Student Volunteer at National Service Scheme ,\\nSpokesperson at VTU StudentPreneurs Club, Captain for VTU Basketball Team', 'generated_questions': '1.  The job requires experience with HuggingFace libraries for model fine-tuning and deploying models on cloud platforms like AWS SageMaker. Your resume highlights projects using ML frameworks and you are Google Cloud certified. Can you describe your most significant experience fine-tuning a pre-trained model and deploying it for a real-world application, detailing the tools and platforms you used and the challenges you faced?\\n2.  Your projects like the Semantic Search Engine and Anuvadak AI Assistant involve NLP and interacting with models. Can you discuss your experience with prompt engineering or optimizing model outputs for specific tasks in any of your projects or internships? How did you iterate on prompts or inputs to improve performance?\\n3.  Your resume mentions a research article publication focusing on real-world applications and emerging technologies, and the job emphasizes a research-driven environment. Can you elaborate on the research you conducted or contributed to, and how your findings could potentially be translated into a practical, deployable AI solution?\\n4.  In developing a project like the Anuvadak AI Assistant or the Smart Green Light system, you likely encountered significant technical challenges (e.g., real-time accuracy, performance optimization). Describe one such challenge and how you approached solving it, including any object-oriented design principles or problem-solving strategies you employed.'}, {'jd_txt': '\\nJob Title: AI/ML Engineer Intern\\n\\nLocation: Bengaluru, India\\n\\nDuartion : 6 Months\\n\\nCompany Overview: IAI Solution is at the forefront of artificial intelligence and machine learning innovation, driving breakthroughs that impact industries worldwide. We are seeking an experienced AI/ML Engineer intern who is deeply knowledgeable in AI and machine learning techniques, and who thrives in a fast-paced, research-driven environment. If you are passionate about AI, have hands-on experience with model fine-tuning and prompt engineering, and want to be part of a team pushing the boundaries of technology, we would love to hear from you.\\n\\nPosition Summary: We are looking for an AI/ML Engineer intern with a strong background in Python, Django, and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, model fine-tuning, and using the HuggingFace libraries. Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications.\\n\\nKey Responsibilities:\\n\\nDevelop, fine-tune, and deploy machine learning models using Python and Django frameworks.\\nApply prompt engineering techniques to optimize model outputs and improve accuracy.\\nUtilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models.\\nWork on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently.\\nCollaborate with research teams to translate cutting-edge AI research into scalable solutions.\\nImplement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions.\\nStay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects.\\nDocument and share findings, best practices, and solutions across the engineering team.\\nQualifications:\\n\\nStrong proficiency in Python and Django.\\nExperience in prompt engineering and fine-tuning AI models.\\nExtensive experience with HuggingFace libraries and similar AI/ML tools.\\nHands-on experience with cloud platforms such as AWS SageMaker for training and deploying models.\\nBackground in AI/ML research, with a preference for candidates from research institutes.\\nDemonstrated experience in training and deploying machine learning models in real-world applications.\\nSolid understanding of object-oriented programming and problem-solving skills.\\nStrong analytical skills and the ability to work independently or in a team environment.\\nExcellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders.\\nPreferred Qualifications:\\n\\nPrevious experience in academic or industrial research, with published work in AI/ML.\\nProven track record of successful AI model deployments and optimizations.\\nPerks & Benefits:\\n\\nWork on groundbreaking AI/ML projects in a collaborative and innovative environment.\\nAccess to state-of-the-art tools and cloud platforms.\\nOpportunities for professional development and continuous learning.\\nComprehensive health and wellness benefits.\\n\\n', 'filename': 'gaurav choudhary_aiml intern.pdf', 'resume_txt': 'GAURAV CHOUDHARY\\ngauravchoudharyiiitg@gmail.com +91-9324132873 /♀nedn:linkedin.com/in/gauraviiitg /gtb:github.com/gauraviiitg\\nEDUCATION\\nINDIAN INSTITUTE OF INFORMATION TECHNOLOGY GUWAHATI\\nBachelor of Technology in Computer Science and Engineering, Graduation: 2025\\nKENDRIYA VIDYALAYA NO. 2 AIR FORCE JODHPUR\\n12th Grade: 88% , 10th Grade (CGPA: 9.6).\\nEXPERIENCE\\nIO CORPORATION LIMITED Nov 2024 - Ongoing\\nMACHINE LEARNING INTERN\\n•Developed a lightweight LLM with 20M+ parameters, optimized inference speed by 30%, and reduced memory\\nfootprint for edge deployments.\\n•Integrated retrieval-augmented generation (RAG) and vector databases, improving chatbot accuracy by 35% and\\nresponse relevance.\\n•Automated 80% of customer inquiries, reducing average response time by 55%, increasing user satisfaction by 40%.\\n•Deployed models on AWS with MLOps pipelines, ensuring scalable and efficient model retraining.\\nBHABHA ATOMIC RESEARCH CENTRE Oct 2023 - Jan 2024\\nRESEARCH PAPER CONTRIBUTOR\\n•Engineered a predictive algorithm to locate radioactive sources with 99.07% accuracy, surpassing the previous 91.37%\\nbenchmark attained.\\n•First author on the research paper detailing this innovative approach, accepted at 67th Department of Atomic\\nEnergy’s Nuclear Physics Symposium.\\nINDEPENDENT PROJECTS\\nAKINATOR /gtbRepository\\nAutomated Customer Issue Categorization and Resolution System\\n•Designed an AI-driven customer support system leveraging SVM, BERT, and RAG to classify and generate responses\\nto customer queries, deployed on Google Cloud for real-time interactions.\\n•Integrated vector search retrieval and fine-tuned BERT models to enhance query relevance, reducing latency by 20%.\\nSHATRANJ /gtbRepository\\nAI-based checkers trainer with enhanced alpha-beta pruning\\n•Implemented multi-layered alpha-beta pruning, reducing move search depth by 40%, leading to 30% faster decision.\\n•Achieved a 93.2% win rate across 300 human matches, demonstrating superior strategic gameplay.\\n•Real-World Impact: Currently operational as AI trainer at KENDRIYA VIDYALAYA benefiting 500+ stu-\\ndents.\\nAAROGYA 6.0 /gtbRepository\\nDBMS-based healthcare portal\\n•Optimized database normalization, reducing redundancy by 70% and improving query speed by 45%\\n•Designed custom time-management functions, enhancing efficiency in offline hospital operations.\\n•Real-World Impact: Being actively used at MIRZA PUBLIC HOSPITAL , Guwahati managing 10,000+\\npatient records.\\nSKILLS\\nMachine Learning & AI Transformer Models, LLM Fine-Tuning, BERT, GPT, RAG, Hugging face\\nDeployment & MLOps AWS, Docker, Kubernetes, CI/CD, Model Optimization, Scalable Cloud AI Deploy-\\nment, TensorFlow, PyTorch, LangChain\\nData & Analytics SQL, Pandas, Hadoop, Spark, Redshift, Tableau, PowerBI\\nPOSITION OF RESPONSIBILITY\\nBRITISH COUNCIL Led India’s delegation for global AI education initiatives, influencing\\npolicies impacting 100,000+ students .\\nNATIONAL SCIENCE CONGRESS Recognized among India’s top young AI researchers, contributing to\\nnational-level research on AI applications in energy sectors .', 'generated_questions': \"1.  Your resume highlights significant experience with Python and ML frameworks like HuggingFace, and projects involving LLMs and RAG systems. The job requires proficiency in Python, Django, and OOP, and experience in prompt engineering. Can you describe your experience with Django, and how you apply object-oriented principles when developing your ML solutions, perhaps referencing one of your projects like the one at IO Corp or Akinator?\\n2.  You mentioned developing a lightweight LLM and integrating RAG for chatbots in your IO Corp internship, and also used RAG with BERT in your Akinator project. Prompt engineering is a key part of optimizing such systems. Can you walk me through your process or specific techniques you used for prompt engineering to improve model outputs and relevance in these projects?\\n3.  Your IO Corp experience involved deploying models on AWS with MLOps pipelines for scalable retraining. The job specifically mentions AWS SageMaker or equivalent platforms for training and deployment. Can you describe your experience using cloud platforms for *training* and deploying ML models at scale, including any challenges you faced and how you addressed them, perhaps comparing approaches if you've used more than one platform?\\n4.  You have a strong research background, demonstrated by your work at BARC, and also significant experience deploying models in real-world applications across various projects. How do you approach translating research concepts or models into practical, scalable solutions ready for deployment? Can you give an example from your experience where you adapted a research idea for a real-world application?\\n5.  In your IO Corp role, you optimized a lightweight LLM for inference speed and memory footprint, aiming for edge deployments. Real-world deployment often requires significant optimization. Can you elaborate on the specific techniques you used to achieve these optimizations (e.g., quantization, pruning, specific architectures, etc.) and how you balanced performance with model size/speed constraints for edge scenarios?\"}, {'jd_txt': '\\nJob Title: AI/ML Engineer Intern\\n\\nLocation: Bengaluru, India\\n\\nDuartion : 6 Months\\n\\nCompany Overview: IAI Solution is at the forefront of artificial intelligence and machine learning innovation, driving breakthroughs that impact industries worldwide. We are seeking an experienced AI/ML Engineer intern who is deeply knowledgeable in AI and machine learning techniques, and who thrives in a fast-paced, research-driven environment. If you are passionate about AI, have hands-on experience with model fine-tuning and prompt engineering, and want to be part of a team pushing the boundaries of technology, we would love to hear from you.\\n\\nPosition Summary: We are looking for an AI/ML Engineer intern with a strong background in Python, Django, and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, model fine-tuning, and using the HuggingFace libraries. Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications.\\n\\nKey Responsibilities:\\n\\nDevelop, fine-tune, and deploy machine learning models using Python and Django frameworks.\\nApply prompt engineering techniques to optimize model outputs and improve accuracy.\\nUtilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models.\\nWork on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently.\\nCollaborate with research teams to translate cutting-edge AI research into scalable solutions.\\nImplement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions.\\nStay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects.\\nDocument and share findings, best practices, and solutions across the engineering team.\\nQualifications:\\n\\nStrong proficiency in Python and Django.\\nExperience in prompt engineering and fine-tuning AI models.\\nExtensive experience with HuggingFace libraries and similar AI/ML tools.\\nHands-on experience with cloud platforms such as AWS SageMaker for training and deploying models.\\nBackground in AI/ML research, with a preference for candidates from research institutes.\\nDemonstrated experience in training and deploying machine learning models in real-world applications.\\nSolid understanding of object-oriented programming and problem-solving skills.\\nStrong analytical skills and the ability to work independently or in a team environment.\\nExcellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders.\\nPreferred Qualifications:\\n\\nPrevious experience in academic or industrial research, with published work in AI/ML.\\nProven track record of successful AI model deployments and optimizations.\\nPerks & Benefits:\\n\\nWork on groundbreaking AI/ML projects in a collaborative and innovative environment.\\nAccess to state-of-the-art tools and cloud platforms.\\nOpportunities for professional development and continuous learning.\\nComprehensive health and wellness benefits.\\n\\n', 'filename': 'BALUSA GNANESH_AIML Intern.pdf', 'resume_txt': ' \\n \\n \\n \\n \\nEDUCATION  GNANESH  BALUSA  \\ngnaneshbalusa016g@gmail.com  |LinkedIn/gnaneshbalusa  | +91 7989131105 \\ngithub.com/gnanesh -16 | Medium/gnaneshbalusa  \\nKoneru  Lakshmaiah  University  Graduation:  May 2025 \\nB-Tech ( Honors)  Electronics  and Communication Engineering  GPA:  8.91 \\n \\n PROFESSIONAL  EXPERIENCE  \\nTihan  IIT Hyderabad  Sangareddy,  (On-site) \\nResearch  Ai Software  Engineer  Intern  July2024  – Dec 2024  \\n• Created  a GUI application  using  Qt to analyze  and modify  GPU  packet  streams  from  the Nvidia  AGX  Orin \\ncontroller  on Linux,  enabling  browser -based  usage  and visualization  for autonomous  vehicle  applications.  \\n• Developed a full-stack  web application with React.js and FastAPI , enabling real -time analysis of GPU packet  \\nstreams  from  Nvidia  AGX  Orin.  I gained  2 years  of experience  developing  web applications , by \\nunderstanding of software development process  while working alongside with M.Tech professionals  \\n• Led cloud  migration  projects  to AWS,  ensuring  smooth  transitions  and optimized  cloud  infrastructure.  \\nand Implemented  Agile  methodologies  to streamline  development  workflows  and enhance  team  \\ncollaboration  \\nPROJECTS  \\nAi-Powered  Automated  Testing  for LLMs  – LLM  Test Automation Suite  (Ongoing  Proje ct) Aziznagar,  HY \\nInterview  Project  January - March  2025  \\n• Engineered  Ai-driven  automated  testing  framework  by Building  a Playwright/PyTest -based  solution  to evaluate \\nLLM behavior, response quality, and accuracy through automated test cases, scenario -driven tests, and \\nperformance metrics (accuracy, precision, recall ) \\n• Deployed sentiment and bias detection on Streamlit cloud and Hugging face using ML classifiers; ensured multi -\\nturn response consistency. Integrated REST/SOAP APIs and handled responses via JSON for logging and \\nreplay.  live working video    \\n• Created  an AI agent  for web searches, task scheduling,  and email  updates  using  Groq  Agno,  DuckDuckGo , \\nFirewall , and Email Tools , while automating nightly test executions with GitHub Actions and Docker.  \\n \\nSpeech  Emotion Recognition  – TimnetO1  (Research, IEEE  Conference)  Gujarat,  India  \\nResearch  Project  August  2024  – November . \\n• Designed  an AI/ML driven  Speech  Emotion  Recognition  (SER)  system  using  TIMNET,  achieving  95%  \\naccuracy in noiseless conditions  \\n• Automated  testing  pipelines  for AI model  evaluation , optimizing  hyperparameters  for real-time speech  analysis.  \\n• Ensured  robustness  with threat  protection mechanisms  to secure  AI-driven  SER data. \\nCloud  Uploader  CLI tool Aziznagar,  HY \\nBackend Developer  April  2023  \\n• Developed  a CLI tool that automates  AWS  SDK  authentication , bucket  selection  or creation,  and file transfers  to AWS \\nS3 general -purpose buckets, simplifying the overall upload process  \\n• Integrated  real-time progress  tracking  and enabled  parallel  uploads  for faster  file transfers,  while  incorporating \\nrobust error handling and logging to facilitate easier debugging  \\n• Cloud  Uploader  is a command -line interface  (CLI)  tool designed  to simplify  uploading  files to AWS  S3 General \\npurpose  buckets.  It automates  the process  of authentication  and file transfer  to buckets.  | GitHub  | Project  | Blog  | \\n \\nCERTIFICATIONS  \\n• AWS Certified Cloud Practitioner  – Amazon Web Services                                                               Issued: Nov 2024                  \\n• Git version  Control                          – GitHub Foundations                                                                     Issued: Feb 2025 \\nSKILLS  \\nLanguage  & Databases : Python  | Redis  | SQL Server  Management  Studio  \\nAI & Machine  Learning  NLP | LLMs  (GPT,  OpenAI),  Groq,  Anthropic,  Agno  (Framework)  \\nAutomation  & Testing : Playwright  | PyTest,  AI Test Frameworks  | Git | GitHub  | Gitlab | CI/CD  | Docker  | Kubernetes  | Jenkins  RESEARCH PUBLICATION  \\n \\n• “Evaluating  Gesture  based  Text Generator  Gloves  System  on Arduino  Platform” \\n• “Comparative  Analysis  of Different  Operational  Logic  Gates  for Cutting -Edge  Technology”  \\n• “Analysis  of TIMNET  Emotional  Modelling  Approach  in Noisy  Environment”  \\n \\nACHIVEMENTS  AND  AWARDS  \\n• Developed  Canvect , a Python  package  for CAN  communication  in autonomous vehicles , with 7.2K+  downloads  \\nand 200+  current  views  (PyPI  | GitHub ). \\n• Finalist , NXP  Hackathon  – Ranked  in the top 5% among  1,500+  teams  in a regional  competition  for innovative \\nAI-driven solutions.  \\n• Tata Imagination  Challenge  – Developed  non-verbal  communication  solutions , showcasing  creativity  and \\nproblem -solving skills.  \\n• Best Research  Paper  Award – Recognized  for AI & Machine  Learning -based  TIMNET  Modelling , awarded  a \\nprize of ₹10,000 .  ', 'generated_questions': \"1.  Your resume mentions experience with Python, FastAPI, and React.js for web application development, and the job description requires proficiency in Python and Django for developing and deploying ML models. Can you describe your experience with Django or other web frameworks specifically for deploying machine learning models, and explain how you would approach integrating an ML model into a web application?\\n2.  The job description emphasizes experience with prompt engineering and fine-tuning AI models, and your projects involve working with LLMs and ML classifiers. Could you elaborate on your practical experience with model fine-tuning techniques and how you've applied prompt engineering to optimize model outputs or evaluate behavior in projects like your LLM Test Automation Suite or Speech Emotion Recognition system?\\n3.  You have demonstrated experience with AWS, including cloud migration and developing a CLI tool for AWS S3, and are an AWS Certified Cloud Practitioner. The role requires experience with AWS SageMaker or similar platforms for training and deploying models. Can you describe your process or workflow for training and deploying an AI model on a cloud platform, and provide an example of a model you've deployed to the cloud, even if not specifically using SageMaker?\\n4.  Your background includes research experience at Tihan IIT Hyderabad and research projects like the Speech Emotion Recognition system, which resulted in publications. This role is in a fast-paced, research-driven environment focused on translating research into scalable solutions. How do you approach staying updated with the latest AI/ML research and integrating new techniques into practical, deployable applications?\"}]\n"
          ]
        }
      ],
      "source": [
        "print(resumes_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "k0YORQy9-22V"
      },
      "outputs": [],
      "source": [
        "#@title data_0\n",
        "data_0 = [{'jd_txt': '\\nJob Title: AI/ML Engineer Intern\\n\\nLocation: Bengaluru, India\\n\\nDuartion : 6 Months\\n\\nCompany Overview: IAI Solution is at the forefront of artificial intelligence and machine learning innovation, driving breakthroughs that impact industries worldwide. We are seeking an experienced AI/ML Engineer intern who is deeply knowledgeable in AI and machine learning techniques, and who thrives in a fast-paced, research-driven environment. If you are passionate about AI, have hands-on experience with model fine-tuning and prompt engineering, and want to be part of a team pushing the boundaries of technology, we would love to hear from you.\\n\\nPosition Summary: We are looking for an AI/ML Engineer intern with a strong background in Python, Django, and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, model fine-tuning, and using the HuggingFace libraries. Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications.\\n\\nKey Responsibilities:\\n\\nDevelop, fine-tune, and deploy machine learning models using Python and Django frameworks.\\nApply prompt engineering techniques to optimize model outputs and improve accuracy.\\nUtilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models.\\nWork on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently.\\nCollaborate with research teams to translate cutting-edge AI research into scalable solutions.\\nImplement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions.\\nStay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects.\\nDocument and share findings, best practices, and solutions across the engineering team.\\nQualifications:\\n\\nStrong proficiency in Python and Django.\\nExperience in prompt engineering and fine-tuning AI models.\\nExtensive experience with HuggingFace libraries and similar AI/ML tools.\\nHands-on experience with cloud platforms such as AWS SageMaker for training and deploying models.\\nBackground in AI/ML research, with a preference for candidates from research institutes.\\nDemonstrated experience in training and deploying machine learning models in real-world applications.\\nSolid understanding of object-oriented programming and problem-solving skills.\\nStrong analytical skills and the ability to work independently or in a team environment.\\nExcellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders.\\nPreferred Qualifications:\\n\\nPrevious experience in academic or industrial research, with published work in AI/ML.\\nProven track record of successful AI model deployments and optimizations.\\nPerks & Benefits:\\n\\nWork on groundbreaking AI/ML projects in a collaborative and innovative environment.\\nAccess to state-of-the-art tools and cloud platforms.\\nOpportunities for professional development and continuous learning.\\nComprehensive health and wellness benefits.\\n\\n', 'filename': 'Mohit Sharma_AIML Engineer.pdf', 'resume_txt': 'Mohit Sharma +91-8504022793\\nRoll No.:M23CSA015 m4mohit21@gmail.com\\nArtificial Intelligence m23csa015@iitj.ac.in\\nComputer Science and Engineering github.com/m4mohit21\\nIndian Institute Of Technology, Jodhpur linkedin.com/in/m4mohitsharma\\nEducation\\nDegree/Certificate Institute/Board CGPA/Percentage Year\\nM.Tech. (AI) Indian Institute of Technology, Jodhpur 7.55 2023-Present\\nB.Tech. (ME) MNIT JAIPUR 8.30 2015-2019\\nSenior Secondary RBSE Board 84.40% 2014\\nSecondary RBSE Board 81.50% 2012\\nExperience\\n•Sadabahar Nidhi Limited June 2021 - June 2023\\nFinancial Data Analyst Intern Bundi, Rajasthan\\n–Entered and managed data for Recurring Deposits (RD) and Fixed Deposits (FD), ensuring accuracy and consistency in\\nfinancial records.\\n–Analyzeddepositorbehaviortoassessfinancialreliability,identifyingindividualswhomaderegulardepositsanddemonstrated\\nresponsibility for loan eligibility.\\n•J.K.Lakshmi Cement July 2019 - Jan. 2020\\nGraduate Engineer Trainee Jaykaypuram\\n–Contributed to the girth gear replacement project and was key in managing a critical 21-day plant shutdown, applying\\nmechanical knowledge to ensure timely completion and efficiency.\\n–Optimized inventory management and workflows by implementing 5S practices in storeroom operations. Monitored machine\\nperformance, conducted root cause analysis, and supported strategic project planning.\\nProjects\\n•Historical Manuscript Restoration\\nVision Transformer-Based Restoration of Old Manuscripts. Github\\n–Trained the T2T-ViT model on H-DIBCO and IGNCA datasets, applying data augmentation to expand the training set to\\n208 images, enabling robust noise reduction and text feature enhancement.\\n–Achieved Precision (96.84%), Recall (86.46%), F1 Score (90.95%), and PSNR (16.64), showcasing significant improvement\\nin readability anddocument clarity.\\n–Tools & technologies used : Python, PyTorch, NumPy, Jupyter Notebook, H-DIBCO/IGNCA datasets.\\n•Supervised Fraud Detection in Insurance Using Social Network Analytics\\nLeveraged social network analytics to improve fraud detection in insurance. Github\\n–Created a random dataset with party and claim associations constraints. Enhanced classification by incorporating network\\nscore-based features , achieving promising results despite limited intrinsic features.\\n–Highlighted potential for integrating social network-based features withintrinsic data for enhanced fraud detection.\\n–Tools:Python, Numpy, Jupyter Notebook, Networkx, Scikit-learn\\n•AARIA: Autonomous Agentic Research and Information Assistant\\nResearch Agent Development with RAG Pipeline, LangGraph and CrewAI Github\\n–Developed a Research Agent with a RAG pipeline andLangGraph for dynamic search, analysis, and summarization, opti-\\nmizing decision-making with graph-based task management.\\n–Integrated Redis, Cohere API, and DuckDuckGo API with tools for academic and web data retrieval.\\n–Implemented a multi-agent architecture withCrewAI for task delegation, incorporating dynamic query generation, selfim-\\nprovement via critique, and efficient feedback handling to enhance scalability and adaptability in research workflows.\\n–Tools:LangGraph, CrewAI, Redis, Cohere API, DuckDuckGo API, Python\\nKey Courses Taken\\n–Deep Learning, Computer Vision, Machine Learning, Social Network Analysis, Ml and Dl Ops, Start a New Venture,\\nAutonomous System, VANET, Digital Image Analysis\\nTechnical Skills\\n–Programming: Python, C, SQL\\n–Tools & OS: Jupyter Notebook, Google Colab, Github, Linux, WandB\\n–Libraries/Frameworks: Pandas, Numpy, Scikit-Learn, Pytorch, Opencv, NetworkX\\nPositions of Responsibility\\n–Teaching Assistant: DLOps, Machine Learning, Human-Machine Interaction, ICS Aug 2023 - Present\\nAchievements\\n–Gate 2023 Qualified Secured 524 gate score in Mechanical Engineering. 2023\\n–HPCL Interview Qualified for HPCL written exam and group task also. 2023\\n–MHRD Scholarship Received State Government Merit Scholarship for Under Graduate 2015-2019', 'generated_questions': \"1.  Your AARIA project involves developing a research agent with a RAG pipeline and multi-agent architecture. How does the experience gained in building this system, particularly in integrating different components and optimizing information retrieval, align with the job requirement of applying prompt engineering techniques and utilizing advanced AI tools?\\n\\n2.  The job description mentions proficiency in Python, Django, and experience with HuggingFace libraries and cloud platforms like AWS SageMaker for training and deploying models. Could you elaborate on your experience level with each of these specific requirements? For areas where your direct experience might be limited, how would you leverage your existing technical skills (e.g., PyTorch, Python) to quickly get up to speed?\\n\\n3.  You've worked on projects like Historical Manuscript Restoration and Supervised Fraud Detection, involving model training and evaluation. Can you walk us through your process for fine-tuning a model for a specific task, and discuss any experience you have with deploying models, including challenges faced in translating research or project work into a deployable solution?\\n\\n4.  Your M.Tech in AI and projects like AARIA indicate a strong interest in AI research, which is preferred for this role. How do you approach staying updated with the latest advancements in the field, and how would you leverage your research background to contribute to translating cutting-edge AI concepts into practical, scalable solutions within our team?\"}, {'jd_txt': '\\nJob Title: AI/ML Engineer Intern\\n\\nLocation: Bengaluru, India\\n\\nDuartion : 6 Months\\n\\nCompany Overview: IAI Solution is at the forefront of artificial intelligence and machine learning innovation, driving breakthroughs that impact industries worldwide. We are seeking an experienced AI/ML Engineer intern who is deeply knowledgeable in AI and machine learning techniques, and who thrives in a fast-paced, research-driven environment. If you are passionate about AI, have hands-on experience with model fine-tuning and prompt engineering, and want to be part of a team pushing the boundaries of technology, we would love to hear from you.\\n\\nPosition Summary: We are looking for an AI/ML Engineer intern with a strong background in Python, Django, and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, model fine-tuning, and using the HuggingFace libraries. Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications.\\n\\nKey Responsibilities:\\n\\nDevelop, fine-tune, and deploy machine learning models using Python and Django frameworks.\\nApply prompt engineering techniques to optimize model outputs and improve accuracy.\\nUtilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models.\\nWork on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently.\\nCollaborate with research teams to translate cutting-edge AI research into scalable solutions.\\nImplement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions.\\nStay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects.\\nDocument and share findings, best practices, and solutions across the engineering team.\\nQualifications:\\n\\nStrong proficiency in Python and Django.\\nExperience in prompt engineering and fine-tuning AI models.\\nExtensive experience with HuggingFace libraries and similar AI/ML tools.\\nHands-on experience with cloud platforms such as AWS SageMaker for training and deploying models.\\nBackground in AI/ML research, with a preference for candidates from research institutes.\\nDemonstrated experience in training and deploying machine learning models in real-world applications.\\nSolid understanding of object-oriented programming and problem-solving skills.\\nStrong analytical skills and the ability to work independently or in a team environment.\\nExcellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders.\\nPreferred Qualifications:\\n\\nPrevious experience in academic or industrial research, with published work in AI/ML.\\nProven track record of successful AI model deployments and optimizations.\\nPerks & Benefits:\\n\\nWork on groundbreaking AI/ML projects in a collaborative and innovative environment.\\nAccess to state-of-the-art tools and cloud platforms.\\nOpportunities for professional development and continuous learning.\\nComprehensive health and wellness benefits.\\n\\n', 'filename': 'Saniya_AIML INTERN.pdf', 'resume_txt': 'Saniya Ladanavar\\n9845967062 |saniyaladanavar123@gmail.com |linkedin |Github\\nEducation\\nVisvesvaraya Technological University Belagavi,Karnataka\\nB.Tech in Computer Science and Business Systems(8.9/10) Dec 2021 - Present\\nRaja Lakhamagouda Science Institute Belagavi,Karnataka\\nClass 12 Science ,(91.16%) June 2020 - July 2021\\nBensons English Medium High School Belagavi,Karnataka\\nHigh School Class 10 ,(90.56%) June 2018 - April 2019\\nExperience\\nResearch Article Publication Aug 2024\\nEuropean Alliance of Innovation Belgaum\\n•The paper highlights practical approaches and advancements contributing to real-world applications and emerging\\ntechnologies.\\nAI Data Intern Sep 2024 – Oct 2024\\nSkypoint.ai On-site , Bengaluru\\n∗Collected, cleaned, and organized datasets to enhance machine learning accuracy and model performance\\nwith fine tuned data pipelines and worked with cross-functional teams to deploy AI solutions while\\nmaintaining comprehensive documentation and presenting insights to US team.\\nSDE Intern Oct 2023 – Nov 2023\\nCNC ITISMU On-site , Belagavi\\n∗Configured and optimized VLANs for secure, segmented networks, enhancing performance and reducing\\ntraffic bottlenecks and Collaborated with IT teams to troubleshoot network issues, ensuring seamless lab\\noperations and efficient VLAN management.\\nProjects\\nAI-Driven Semantic Search Engine |AI/ML link\\n∗Built a semantic search engine using BERT and Elasticsearch , Integrated NLP models to enhance query\\nintent detection by 30% and deliver precise, context-aware results and Optimized indexing, query tuning, and\\nsearch relevance for large datasets, ensuring high-performance search operations.\\nAnuvadak - AI Assistant |Machine Learning, Python link\\n∗Engineered an AI-powered assistant that converts sign language into text with 80% real-time accuracy ,\\nenhancing accessibility and Integrated machine learning, computer vision, and NLP for seamless gesture\\nrecognition and optimized , system performance for inclusive communication solutions.\\nSmart Green Light |AI/ML link\\n∗Developed an AI-powered traffic management system to optimize signal timings based on real-time traffic flow,\\nreducing congestion and improving efficiency through data-driven decision-making.\\nAWARDS AND ACHIEVEMENTS\\nGoogle Cloud Certified : link - Data, ML, AI, Generative AI, Networking secuirity and Cloud Computing Google\\nDevelopers Group (GDG) Lead VTU : Fostering a vibrant tech community through events and projects\\nStartup Mahakumbh - India’s largest startup event : Represented my univeristy (VTU) solely from my\\nBatch’25\\nAcademic excellence: : Best Student of the year (All Rounder) and awards in leadership, debate, public speaking.\\nConference Paper Presentation : 1st International Conference of Advanced Computing Technologies 2024.Skills\\nLanguages/Skills : C++, Python, Machine Learning, Web Development, Blockchain, Mysql, Powerbi, Excel\\nFrameworks : Django, Reactjs, Nodejs, streamlit, Tensorflow, Keras, scikit-learn, Mat-plotlib, OpenCV\\nDeveloper Tools and Platforms : VS Code, Jupyter Notebook, Notepad++, Linux, Unix\\nInterpersonal skills : Public Speaking, Leadership, Effective Communicator, Team Collaboration, Presentation\\nPosition of Responsibility\\nLead at Technical and Personality Development Clubs , Student Volunteer at National Service Scheme ,\\nSpokesperson at VTU StudentPreneurs Club, Captain for VTU Basketball Team', 'generated_questions': '1.  The job requires experience with HuggingFace libraries for model fine-tuning and deploying models on cloud platforms like AWS SageMaker. Your resume highlights projects using ML frameworks and you are Google Cloud certified. Can you describe your most significant experience fine-tuning a pre-trained model and deploying it for a real-world application, detailing the tools and platforms you used and the challenges you faced?\\n2.  Your projects like the Semantic Search Engine and Anuvadak AI Assistant involve NLP and interacting with models. Can you discuss your experience with prompt engineering or optimizing model outputs for specific tasks in any of your projects or internships? How did you iterate on prompts or inputs to improve performance?\\n3.  Your resume mentions a research article publication focusing on real-world applications and emerging technologies, and the job emphasizes a research-driven environment. Can you elaborate on the research you conducted or contributed to, and how your findings could potentially be translated into a practical, deployable AI solution?\\n4.  In developing a project like the Anuvadak AI Assistant or the Smart Green Light system, you likely encountered significant technical challenges (e.g., real-time accuracy, performance optimization). Describe one such challenge and how you approached solving it, including any object-oriented design principles or problem-solving strategies you employed.'}, {'jd_txt': '\\nJob Title: AI/ML Engineer Intern\\n\\nLocation: Bengaluru, India\\n\\nDuartion : 6 Months\\n\\nCompany Overview: IAI Solution is at the forefront of artificial intelligence and machine learning innovation, driving breakthroughs that impact industries worldwide. We are seeking an experienced AI/ML Engineer intern who is deeply knowledgeable in AI and machine learning techniques, and who thrives in a fast-paced, research-driven environment. If you are passionate about AI, have hands-on experience with model fine-tuning and prompt engineering, and want to be part of a team pushing the boundaries of technology, we would love to hear from you.\\n\\nPosition Summary: We are looking for an AI/ML Engineer intern with a strong background in Python, Django, and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, model fine-tuning, and using the HuggingFace libraries. Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications.\\n\\nKey Responsibilities:\\n\\nDevelop, fine-tune, and deploy machine learning models using Python and Django frameworks.\\nApply prompt engineering techniques to optimize model outputs and improve accuracy.\\nUtilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models.\\nWork on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently.\\nCollaborate with research teams to translate cutting-edge AI research into scalable solutions.\\nImplement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions.\\nStay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects.\\nDocument and share findings, best practices, and solutions across the engineering team.\\nQualifications:\\n\\nStrong proficiency in Python and Django.\\nExperience in prompt engineering and fine-tuning AI models.\\nExtensive experience with HuggingFace libraries and similar AI/ML tools.\\nHands-on experience with cloud platforms such as AWS SageMaker for training and deploying models.\\nBackground in AI/ML research, with a preference for candidates from research institutes.\\nDemonstrated experience in training and deploying machine learning models in real-world applications.\\nSolid understanding of object-oriented programming and problem-solving skills.\\nStrong analytical skills and the ability to work independently or in a team environment.\\nExcellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders.\\nPreferred Qualifications:\\n\\nPrevious experience in academic or industrial research, with published work in AI/ML.\\nProven track record of successful AI model deployments and optimizations.\\nPerks & Benefits:\\n\\nWork on groundbreaking AI/ML projects in a collaborative and innovative environment.\\nAccess to state-of-the-art tools and cloud platforms.\\nOpportunities for professional development and continuous learning.\\nComprehensive health and wellness benefits.\\n\\n', 'filename': 'gaurav choudhary_aiml intern.pdf', 'resume_txt': 'GAURAV CHOUDHARY\\ngauravchoudharyiiitg@gmail.com +91-9324132873 /♀nedn:linkedin.com/in/gauraviiitg /gtb:github.com/gauraviiitg\\nEDUCATION\\nINDIAN INSTITUTE OF INFORMATION TECHNOLOGY GUWAHATI\\nBachelor of Technology in Computer Science and Engineering, Graduation: 2025\\nKENDRIYA VIDYALAYA NO. 2 AIR FORCE JODHPUR\\n12th Grade: 88% , 10th Grade (CGPA: 9.6).\\nEXPERIENCE\\nIO CORPORATION LIMITED Nov 2024 - Ongoing\\nMACHINE LEARNING INTERN\\n•Developed a lightweight LLM with 20M+ parameters, optimized inference speed by 30%, and reduced memory\\nfootprint for edge deployments.\\n•Integrated retrieval-augmented generation (RAG) and vector databases, improving chatbot accuracy by 35% and\\nresponse relevance.\\n•Automated 80% of customer inquiries, reducing average response time by 55%, increasing user satisfaction by 40%.\\n•Deployed models on AWS with MLOps pipelines, ensuring scalable and efficient model retraining.\\nBHABHA ATOMIC RESEARCH CENTRE Oct 2023 - Jan 2024\\nRESEARCH PAPER CONTRIBUTOR\\n•Engineered a predictive algorithm to locate radioactive sources with 99.07% accuracy, surpassing the previous 91.37%\\nbenchmark attained.\\n•First author on the research paper detailing this innovative approach, accepted at 67th Department of Atomic\\nEnergy’s Nuclear Physics Symposium.\\nINDEPENDENT PROJECTS\\nAKINATOR /gtbRepository\\nAutomated Customer Issue Categorization and Resolution System\\n•Designed an AI-driven customer support system leveraging SVM, BERT, and RAG to classify and generate responses\\nto customer queries, deployed on Google Cloud for real-time interactions.\\n•Integrated vector search retrieval and fine-tuned BERT models to enhance query relevance, reducing latency by 20%.\\nSHATRANJ /gtbRepository\\nAI-based checkers trainer with enhanced alpha-beta pruning\\n•Implemented multi-layered alpha-beta pruning, reducing move search depth by 40%, leading to 30% faster decision.\\n•Achieved a 93.2% win rate across 300 human matches, demonstrating superior strategic gameplay.\\n•Real-World Impact: Currently operational as AI trainer at KENDRIYA VIDYALAYA benefiting 500+ stu-\\ndents.\\nAAROGYA 6.0 /gtbRepository\\nDBMS-based healthcare portal\\n•Optimized database normalization, reducing redundancy by 70% and improving query speed by 45%\\n•Designed custom time-management functions, enhancing efficiency in offline hospital operations.\\n•Real-World Impact: Being actively used at MIRZA PUBLIC HOSPITAL , Guwahati managing 10,000+\\npatient records.\\nSKILLS\\nMachine Learning & AI Transformer Models, LLM Fine-Tuning, BERT, GPT, RAG, Hugging face\\nDeployment & MLOps AWS, Docker, Kubernetes, CI/CD, Model Optimization, Scalable Cloud AI Deploy-\\nment, TensorFlow, PyTorch, LangChain\\nData & Analytics SQL, Pandas, Hadoop, Spark, Redshift, Tableau, PowerBI\\nPOSITION OF RESPONSIBILITY\\nBRITISH COUNCIL Led India’s delegation for global AI education initiatives, influencing\\npolicies impacting 100,000+ students .\\nNATIONAL SCIENCE CONGRESS Recognized among India’s top young AI researchers, contributing to\\nnational-level research on AI applications in energy sectors .', 'generated_questions': \"1.  Your resume highlights significant experience with Python and ML frameworks like HuggingFace, and projects involving LLMs and RAG systems. The job requires proficiency in Python, Django, and OOP, and experience in prompt engineering. Can you describe your experience with Django, and how you apply object-oriented principles when developing your ML solutions, perhaps referencing one of your projects like the one at IO Corp or Akinator?\\n2.  You mentioned developing a lightweight LLM and integrating RAG for chatbots in your IO Corp internship, and also used RAG with BERT in your Akinator project. Prompt engineering is a key part of optimizing such systems. Can you walk me through your process or specific techniques you used for prompt engineering to improve model outputs and relevance in these projects?\\n3.  Your IO Corp experience involved deploying models on AWS with MLOps pipelines for scalable retraining. The job specifically mentions AWS SageMaker or equivalent platforms for training and deployment. Can you describe your experience using cloud platforms for *training* and deploying ML models at scale, including any challenges you faced and how you addressed them, perhaps comparing approaches if you've used more than one platform?\\n4.  You have a strong research background, demonstrated by your work at BARC, and also significant experience deploying models in real-world applications across various projects. How do you approach translating research concepts or models into practical, scalable solutions ready for deployment? Can you give an example from your experience where you adapted a research idea for a real-world application?\\n5.  In your IO Corp role, you optimized a lightweight LLM for inference speed and memory footprint, aiming for edge deployments. Real-world deployment often requires significant optimization. Can you elaborate on the specific techniques you used to achieve these optimizations (e.g., quantization, pruning, specific architectures, etc.) and how you balanced performance with model size/speed constraints for edge scenarios?\"}, {'jd_txt': '\\nJob Title: AI/ML Engineer Intern\\n\\nLocation: Bengaluru, India\\n\\nDuartion : 6 Months\\n\\nCompany Overview: IAI Solution is at the forefront of artificial intelligence and machine learning innovation, driving breakthroughs that impact industries worldwide. We are seeking an experienced AI/ML Engineer intern who is deeply knowledgeable in AI and machine learning techniques, and who thrives in a fast-paced, research-driven environment. If you are passionate about AI, have hands-on experience with model fine-tuning and prompt engineering, and want to be part of a team pushing the boundaries of technology, we would love to hear from you.\\n\\nPosition Summary: We are looking for an AI/ML Engineer intern with a strong background in Python, Django, and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, model fine-tuning, and using the HuggingFace libraries. Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications.\\n\\nKey Responsibilities:\\n\\nDevelop, fine-tune, and deploy machine learning models using Python and Django frameworks.\\nApply prompt engineering techniques to optimize model outputs and improve accuracy.\\nUtilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models.\\nWork on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently.\\nCollaborate with research teams to translate cutting-edge AI research into scalable solutions.\\nImplement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions.\\nStay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects.\\nDocument and share findings, best practices, and solutions across the engineering team.\\nQualifications:\\n\\nStrong proficiency in Python and Django.\\nExperience in prompt engineering and fine-tuning AI models.\\nExtensive experience with HuggingFace libraries and similar AI/ML tools.\\nHands-on experience with cloud platforms such as AWS SageMaker for training and deploying models.\\nBackground in AI/ML research, with a preference for candidates from research institutes.\\nDemonstrated experience in training and deploying machine learning models in real-world applications.\\nSolid understanding of object-oriented programming and problem-solving skills.\\nStrong analytical skills and the ability to work independently or in a team environment.\\nExcellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders.\\nPreferred Qualifications:\\n\\nPrevious experience in academic or industrial research, with published work in AI/ML.\\nProven track record of successful AI model deployments and optimizations.\\nPerks & Benefits:\\n\\nWork on groundbreaking AI/ML projects in a collaborative and innovative environment.\\nAccess to state-of-the-art tools and cloud platforms.\\nOpportunities for professional development and continuous learning.\\nComprehensive health and wellness benefits.\\n\\n', 'filename': 'BALUSA GNANESH_AIML Intern.pdf', 'resume_txt': ' \\n \\n \\n \\n \\nEDUCATION  GNANESH  BALUSA  \\ngnaneshbalusa016g@gmail.com  |LinkedIn/gnaneshbalusa  | +91 7989131105 \\ngithub.com/gnanesh -16 | Medium/gnaneshbalusa  \\nKoneru  Lakshmaiah  University  Graduation:  May 2025 \\nB-Tech ( Honors)  Electronics  and Communication Engineering  GPA:  8.91 \\n \\n PROFESSIONAL  EXPERIENCE  \\nTihan  IIT Hyderabad  Sangareddy,  (On-site) \\nResearch  Ai Software  Engineer  Intern  July2024  – Dec 2024  \\n• Created  a GUI application  using  Qt to analyze  and modify  GPU  packet  streams  from  the Nvidia  AGX  Orin \\ncontroller  on Linux,  enabling  browser -based  usage  and visualization  for autonomous  vehicle  applications.  \\n• Developed a full-stack  web application with React.js and FastAPI , enabling real -time analysis of GPU packet  \\nstreams  from  Nvidia  AGX  Orin.  I gained  2 years  of experience  developing  web applications , by \\nunderstanding of software development process  while working alongside with M.Tech professionals  \\n• Led cloud  migration  projects  to AWS,  ensuring  smooth  transitions  and optimized  cloud  infrastructure.  \\nand Implemented  Agile  methodologies  to streamline  development  workflows  and enhance  team  \\ncollaboration  \\nPROJECTS  \\nAi-Powered  Automated  Testing  for LLMs  – LLM  Test Automation Suite  (Ongoing  Proje ct) Aziznagar,  HY \\nInterview  Project  January - March  2025  \\n• Engineered  Ai-driven  automated  testing  framework  by Building  a Playwright/PyTest -based  solution  to evaluate \\nLLM behavior, response quality, and accuracy through automated test cases, scenario -driven tests, and \\nperformance metrics (accuracy, precision, recall ) \\n• Deployed sentiment and bias detection on Streamlit cloud and Hugging face using ML classifiers; ensured multi -\\nturn response consistency. Integrated REST/SOAP APIs and handled responses via JSON for logging and \\nreplay.  live working video    \\n• Created  an AI agent  for web searches, task scheduling,  and email  updates  using  Groq  Agno,  DuckDuckGo , \\nFirewall , and Email Tools , while automating nightly test executions with GitHub Actions and Docker.  \\n \\nSpeech  Emotion Recognition  – TimnetO1  (Research, IEEE  Conference)  Gujarat,  India  \\nResearch  Project  August  2024  – November . \\n• Designed  an AI/ML driven  Speech  Emotion  Recognition  (SER)  system  using  TIMNET,  achieving  95%  \\naccuracy in noiseless conditions  \\n• Automated  testing  pipelines  for AI model  evaluation , optimizing  hyperparameters  for real-time speech  analysis.  \\n• Ensured  robustness  with threat  protection mechanisms  to secure  AI-driven  SER data. \\nCloud  Uploader  CLI tool Aziznagar,  HY \\nBackend Developer  April  2023  \\n• Developed  a CLI tool that automates  AWS  SDK  authentication , bucket  selection  or creation,  and file transfers  to AWS \\nS3 general -purpose buckets, simplifying the overall upload process  \\n• Integrated  real-time progress  tracking  and enabled  parallel  uploads  for faster  file transfers,  while  incorporating \\nrobust error handling and logging to facilitate easier debugging  \\n• Cloud  Uploader  is a command -line interface  (CLI)  tool designed  to simplify  uploading  files to AWS  S3 General \\npurpose  buckets.  It automates  the process  of authentication  and file transfer  to buckets.  | GitHub  | Project  | Blog  | \\n \\nCERTIFICATIONS  \\n• AWS Certified Cloud Practitioner  – Amazon Web Services                                                               Issued: Nov 2024                  \\n• Git version  Control                          – GitHub Foundations                                                                     Issued: Feb 2025 \\nSKILLS  \\nLanguage  & Databases : Python  | Redis  | SQL Server  Management  Studio  \\nAI & Machine  Learning  NLP | LLMs  (GPT,  OpenAI),  Groq,  Anthropic,  Agno  (Framework)  \\nAutomation  & Testing : Playwright  | PyTest,  AI Test Frameworks  | Git | GitHub  | Gitlab | CI/CD  | Docker  | Kubernetes  | Jenkins  RESEARCH PUBLICATION  \\n \\n• “Evaluating  Gesture  based  Text Generator  Gloves  System  on Arduino  Platform” \\n• “Comparative  Analysis  of Different  Operational  Logic  Gates  for Cutting -Edge  Technology”  \\n• “Analysis  of TIMNET  Emotional  Modelling  Approach  in Noisy  Environment”  \\n \\nACHIVEMENTS  AND  AWARDS  \\n• Developed  Canvect , a Python  package  for CAN  communication  in autonomous vehicles , with 7.2K+  downloads  \\nand 200+  current  views  (PyPI  | GitHub ). \\n• Finalist , NXP  Hackathon  – Ranked  in the top 5% among  1,500+  teams  in a regional  competition  for innovative \\nAI-driven solutions.  \\n• Tata Imagination  Challenge  – Developed  non-verbal  communication  solutions , showcasing  creativity  and \\nproblem -solving skills.  \\n• Best Research  Paper  Award – Recognized  for AI & Machine  Learning -based  TIMNET  Modelling , awarded  a \\nprize of ₹10,000 .  ', 'generated_questions': \"1.  Your resume mentions experience with Python, FastAPI, and React.js for web application development, and the job description requires proficiency in Python and Django for developing and deploying ML models. Can you describe your experience with Django or other web frameworks specifically for deploying machine learning models, and explain how you would approach integrating an ML model into a web application?\\n2.  The job description emphasizes experience with prompt engineering and fine-tuning AI models, and your projects involve working with LLMs and ML classifiers. Could you elaborate on your practical experience with model fine-tuning techniques and how you've applied prompt engineering to optimize model outputs or evaluate behavior in projects like your LLM Test Automation Suite or Speech Emotion Recognition system?\\n3.  You have demonstrated experience with AWS, including cloud migration and developing a CLI tool for AWS S3, and are an AWS Certified Cloud Practitioner. The role requires experience with AWS SageMaker or similar platforms for training and deploying models. Can you describe your process or workflow for training and deploying an AI model on a cloud platform, and provide an example of a model you've deployed to the cloud, even if not specifically using SageMaker?\\n4.  Your background includes research experience at Tihan IIT Hyderabad and research projects like the Speech Emotion Recognition system, which resulted in publications. This role is in a fast-paced, research-driven environment focused on translating research into scalable solutions. How do you approach staying updated with the latest AI/ML research and integrating new techniques into practical, deployable applications?\"}]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzjicthQ-6L3",
        "outputId": "abd165de-801e-4ed4-a21d-8783fae2a703"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.  Your AARIA project involves developing a research agent with a RAG pipeline and multi-agent architecture. How does the experience gained in building this system, particularly in integrating different components and optimizing information retrieval, align with the job requirement of applying prompt engineering techniques and utilizing advanced AI tools?\n",
            "\n",
            "2.  The job description mentions proficiency in Python, Django, and experience with HuggingFace libraries and cloud platforms like AWS SageMaker for training and deploying models. Could you elaborate on your experience level with each of these specific requirements? For areas where your direct experience might be limited, how would you leverage your existing technical skills (e.g., PyTorch, Python) to quickly get up to speed?\n",
            "\n",
            "3.  You've worked on projects like Historical Manuscript Restoration and Supervised Fraud Detection, involving model training and evaluation. Can you walk us through your process for fine-tuning a model for a specific task, and discuss any experience you have with deploying models, including challenges faced in translating research or project work into a deployable solution?\n",
            "\n",
            "4.  Your M.Tech in AI and projects like AARIA indicate a strong interest in AI research, which is preferred for this role. How do you approach staying updated with the latest advancements in the field, and how would you leverage your research background to contribute to translating cutting-edge AI concepts into practical, scalable solutions within our team?\n"
          ]
        }
      ],
      "source": [
        "print(data_0[0]['generated_questions'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SufIlOCeYAwj"
      },
      "outputs": [],
      "source": [
        "data = [{'jd_txt': '\\nJob Title: AI/ML Engineer Intern\\n\\nLocation: Bengaluru, India\\n\\nDuartion : 6 Months\\n\\nCompany Overview: IAI Solution is at the forefront of artificial intelligence and machine learning innovation, driving breakthroughs that impact industries worldwide. We are seeking an experienced AI/ML Engineer intern who is deeply knowledgeable in AI and machine learning techniques, and who thrives in a fast-paced, research-driven environment. If you are passionate about AI, have hands-on experience with model fine-tuning and prompt engineering, and want to be part of a team pushing the boundaries of technology, we would love to hear from you.\\n\\nPosition Summary: We are looking for an AI/ML Engineer intern with a strong background in Python, Django, and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, model fine-tuning, and using the HuggingFace libraries. Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications.\\n\\nKey Responsibilities:\\n\\nDevelop, fine-tune, and deploy machine learning models using Python and Django frameworks.\\nApply prompt engineering techniques to optimize model outputs and improve accuracy.\\nUtilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models.\\nWork on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently.\\nCollaborate with research teams to translate cutting-edge AI research into scalable solutions.\\nImplement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions.\\nStay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects.\\nDocument and share findings, best practices, and solutions across the engineering team.\\nQualifications:\\n\\nStrong proficiency in Python and Django.\\nExperience in prompt engineering and fine-tuning AI models.\\nExtensive experience with HuggingFace libraries and similar AI/ML tools.\\nHands-on experience with cloud platforms such as AWS SageMaker for training and deploying models.\\nBackground in AI/ML research, with a preference for candidates from research institutes.\\nDemonstrated experience in training and deploying machine learning models in real-world applications.\\nSolid understanding of object-oriented programming and problem-solving skills.\\nStrong analytical skills and the ability to work independently or in a team environment.\\nExcellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders.\\nPreferred Qualifications:\\n\\nPrevious experience in academic or industrial research, with published work in AI/ML.\\nProven track record of successful AI model deployments and optimizations.\\nPerks & Benefits:\\n\\nWork on groundbreaking AI/ML projects in a collaborative and innovative environment.\\nAccess to state-of-the-art tools and cloud platforms.\\nOpportunities for professional development and continuous learning.\\nComprehensive health and wellness benefits.\\n\\n',\n",
        "         'filename': 'Lisha Rudani_AIML.pdf',\n",
        "         'resume_txt': 'Lisha  Rudani.  |+91  7798922908| edulisha007@gmail.com | Portfolio  | LinkedIn  |GitHub  \\nEDUCATION:  \\nThe New  College,  Kolhapur,Maharashtra,  India  March,  2019  \\nBCA \\nSKILLS  \\n \\n● Python  \\n● Machine  Learning  \\n● Deep  Learning  \\n● NLP \\n● Hugging face  \\n \\n \\nEXPERIENCE:  ● Rag \\n● Fine Tunning  \\n● Large  Language  Models  - \\nLLAMA,OpenAI,  Claude  \\n● OpenCv  ● FastAPI  \\n● VectorD atabases -\\nPinecone, Faiss, \\nChromadb  \\n● LangChain ,LangGraph,  \\nLlamindex,Langsmit h\\nAI/ML Engineer Intern, UpcomingVerse Tech Labs -Indore ,India.                                                             Feb2025 -March2025  \\nDetecting Facial Expression Analysis  of Interviewer  [Python  | OpenCV  | Deep Learning ]  \\n• Implemented Facial Expression Analysis using OpenCV for real -time emotion detection through \\nwebcam input.  \\n• Applied Haar Cascade  for face detection and trained a CNN model to classify expressions like happy, \\nsad, angry, and neutral.  \\nAI/ML Engineer Intern , Netzwerk AI - Bengaluru ,India .                                                                     Aug2024 -Jan2025  \\nTargeted  Advertisement  based  on Customer  Segment  [Python,NLP]                                    \\n• Used  python  libraries  Numpy,Pandas  for data  cleaning  ,Matplotlib ,Seaborn  for data  visualization.  \\n• Used  sophisticated  algorithms  such  as BERT  and WordCloud  to conduct  sentiment  analysis,  resulting  in \\nsignificantly enhanced insights.Resulting  in a 40%  increase  in accurate  information  retrieval  efficiency.  \\nResulting  in a 17%  increase  in marketing effectiveness.   \\nBusiness  Head  \\nMina  Soap  Industry ,Kolhapur                                                                                                          Jun 2019  - July 2024 \\n• Developed  and executed  comprehensive  business  strategies  to drive  organizational  growth  and achieve  long - \\nterm objectives.Directed  strategic  initiatives  that led to a 25%  year -over -year  growth  in revenue  by \\nidentifying  new  market opportunities and enhancing product offerings.  \\nPROJECT  EXPERIENCE  \\nWater Quality Index  Prediction [Python|Machine  Learning  ]|Github                                                     Dec 2024-Jan2025  \\n• Developed a Water Quality Index Prediction model using Python , Exploratory  Data  Analysis  (EDA),  machine \\nlearning algorithms.  \\n• Implemented Decision Tree  and Random Forest Classifier  to assess water quality based on multiple \\nparameters.Achieved 97%  prediction accuracy, enabling effective classification of water quality levels.  \\n• Evaluated  model  performance  using  accuracy,  precision,  recall,  and confusion  matrix  for insights.  \\nMulti -Agent Doctors  Appointment Booking System  [Python|Lang Graph |FastAPI |]|Github                Jan 2025 -Feb 2025  \\n• Built an AI -Powered Multi -Agent System for Doctor Appointment Booking using LangGraph, FastAPI, \\nStreamlit.  \\n• Handled real -time user queries related to doctor availability, specialization, and appointment \\nscheduling.Enabled seamless interaction and intelligent task coordination across agents for an \\nefficient healthcare experience.  \\nQuestion  Answring Rag Application  [Python| Haystack |Mistral AI|Pinecone|FastA PI]|Githu b     March  2025 -April 2025  \\n• Built a Question Answering RAG  application using Python, Haystack, Mistral AI,  and FastAPI.  \\n• Implemented Pinecone  for high -speed vector search and context retrieval.  \\n• Combined semantic search with LLMs to deliver accurate, real -time answers. Built  a scalable,  interactive  \\ninterface  with  Streamlit . \\nCERTIFICATIONS  / AWARDS:  \\n• Foundational  Generative  AI by iNeuron.  July,2024  ',\n",
        "         'generated_questions': \"1.  The job description emphasizes proficiency in Django and experience with cloud platforms like AWS SageMaker for training and deploying models. Based on your background, which includes Python and FastAPI experience but doesn't explicitly mention Django or cloud MLOps platforms, how would you approach quickly gaining proficiency in these areas to meet the demands of this role?\\n2.  Your resume highlights skills in Fine Tuning, Prompt Engineering (RAG), and using HuggingFace libraries. Could you describe a specific instance where you applied fine-tuning or advanced prompt engineering techniques to improve the performance or behavior of a language model or other AI model? Please elaborate on the problem, your approach using these tools, and the outcome.\\n3.  The role requires deploying AI models in real-world applications and potentially collaborating with research teams. Drawing from your project experience, like the RAG application or the Multi-Agent system, how did you consider factors like scalability, reliability, or integration for potential deployment? How do you typically approach translating theoretical AI concepts or research findings into practical, working code?\\n4.  The job description mentions the importance of Object-Oriented Programming (OOP) and problem-solving skills. Can you provide an example from one of your projects, perhaps the Multi-Agent System or the RAG application, where you applied OOP principles to structure your code and solve a specific technical challenge?\"},\n",
        "        {'jd_txt': '\\nJob Title: AI/ML Engineer Intern\\n\\nLocation: Bengaluru, India\\n\\nDuartion : 6 Months\\n\\nCompany Overview: IAI Solution is at the forefront of artificial intelligence and machine learning innovation, driving breakthroughs that impact industries worldwide. We are seeking an experienced AI/ML Engineer intern who is deeply knowledgeable in AI and machine learning techniques, and who thrives in a fast-paced, research-driven environment. If you are passionate about AI, have hands-on experience with model fine-tuning and prompt engineering, and want to be part of a team pushing the boundaries of technology, we would love to hear from you.\\n\\nPosition Summary: We are looking for an AI/ML Engineer intern with a strong background in Python, Django, and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, model fine-tuning, and using the HuggingFace libraries. Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications.\\n\\nKey Responsibilities:\\n\\nDevelop, fine-tune, and deploy machine learning models using Python and Django frameworks.\\nApply prompt engineering techniques to optimize model outputs and improve accuracy.\\nUtilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models.\\nWork on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently.\\nCollaborate with research teams to translate cutting-edge AI research into scalable solutions.\\nImplement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions.\\nStay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects.\\nDocument and share findings, best practices, and solutions across the engineering team.\\nQualifications:\\n\\nStrong proficiency in Python and Django.\\nExperience in prompt engineering and fine-tuning AI models.\\nExtensive experience with HuggingFace libraries and similar AI/ML tools.\\nHands-on experience with cloud platforms such as AWS SageMaker for training and deploying models.\\nBackground in AI/ML research, with a preference for candidates from research institutes.\\nDemonstrated experience in training and deploying machine learning models in real-world applications.\\nSolid understanding of object-oriented programming and problem-solving skills.\\nStrong analytical skills and the ability to work independently or in a team environment.\\nExcellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders.\\nPreferred Qualifications:\\n\\nPrevious experience in academic or industrial research, with published work in AI/ML.\\nProven track record of successful AI model deployments and optimizations.\\nPerks & Benefits:\\n\\nWork on groundbreaking AI/ML projects in a collaborative and innovative environment.\\nAccess to state-of-the-art tools and cloud platforms.\\nOpportunities for professional development and continuous learning.\\nComprehensive health and wellness benefits.\\n\\n',\n",
        "         'filename': 'Mohit Sharma_AIML Engineer.pdf',\n",
        "         'resume_txt': 'Mohit Sharma +91-8504022793\\nRoll No.:M23CSA015 m4mohit21@gmail.com\\nArtificial Intelligence m23csa015@iitj.ac.in\\nComputer Science and Engineering github.com/m4mohit21\\nIndian Institute Of Technology, Jodhpur linkedin.com/in/m4mohitsharma\\nEducation\\nDegree/Certificate Institute/Board CGPA/Percentage Year\\nM.Tech. (AI) Indian Institute of Technology, Jodhpur 7.55 2023-Present\\nB.Tech. (ME) MNIT JAIPUR 8.30 2015-2019\\nSenior Secondary RBSE Board 84.40% 2014\\nSecondary RBSE Board 81.50% 2012\\nExperience\\n•Sadabahar Nidhi Limited June 2021 - June 2023\\nFinancial Data Analyst Intern Bundi, Rajasthan\\n–Entered and managed data for Recurring Deposits (RD) and Fixed Deposits (FD), ensuring accuracy and consistency in\\nfinancial records.\\n–Analyzeddepositorbehaviortoassessfinancialreliability,identifyingindividualswhomaderegulardepositsanddemonstrated\\nresponsibility for loan eligibility.\\n•J.K.Lakshmi Cement July 2019 - Jan. 2020\\nGraduate Engineer Trainee Jaykaypuram\\n–Contributed to the girth gear replacement project and was key in managing a critical 21-day plant shutdown, applying\\nmechanical knowledge to ensure timely completion and efficiency.\\n–Optimized inventory management and workflows by implementing 5S practices in storeroom operations. Monitored machine\\nperformance, conducted root cause analysis, and supported strategic project planning.\\nProjects\\n•Historical Manuscript Restoration\\nVision Transformer-Based Restoration of Old Manuscripts. Github\\n–Trained the T2T-ViT model on H-DIBCO and IGNCA datasets, applying data augmentation to expand the training set to\\n208 images, enabling robust noise reduction and text feature enhancement.\\n–Achieved Precision (96.84%), Recall (86.46%), F1 Score (90.95%), and PSNR (16.64), showcasing significant improvement\\nin readability anddocument clarity.\\n–Tools & technologies used : Python, PyTorch, NumPy, Jupyter Notebook, H-DIBCO/IGNCA datasets.\\n•Supervised Fraud Detection in Insurance Using Social Network Analytics\\nLeveraged social network analytics to improve fraud detection in insurance. Github\\n–Created a random dataset with party and claim associations constraints. Enhanced classification by incorporating network\\nscore-based features , achieving promising results despite limited intrinsic features.\\n–Highlighted potential for integrating social network-based features withintrinsic data for enhanced fraud detection.\\n–Tools:Python, Numpy, Jupyter Notebook, Networkx, Scikit-learn\\n•AARIA: Autonomous Agentic Research and Information Assistant\\nResearch Agent Development with RAG Pipeline, LangGraph and CrewAI Github\\n–Developed a Research Agent with a RAG pipeline andLangGraph for dynamic search, analysis, and summarization, opti-\\nmizing decision-making with graph-based task management.\\n–Integrated Redis, Cohere API, and DuckDuckGo API with tools for academic and web data retrieval.\\n–Implemented a multi-agent architecture withCrewAI for task delegation, incorporating dynamic query generation, selfim-\\nprovement via critique, and efficient feedback handling to enhance scalability and adaptability in research workflows.\\n–Tools:LangGraph, CrewAI, Redis, Cohere API, DuckDuckGo API, Python\\nKey Courses Taken\\n–Deep Learning, Computer Vision, Machine Learning, Social Network Analysis, Ml and Dl Ops, Start a New Venture,\\nAutonomous System, VANET, Digital Image Analysis\\nTechnical Skills\\n–Programming: Python, C, SQL\\n–Tools & OS: Jupyter Notebook, Google Colab, Github, Linux, WandB\\n–Libraries/Frameworks: Pandas, Numpy, Scikit-Learn, Pytorch, Opencv, NetworkX\\nPositions of Responsibility\\n–Teaching Assistant: DLOps, Machine Learning, Human-Machine Interaction, ICS Aug 2023 - Present\\nAchievements\\n–Gate 2023 Qualified Secured 524 gate score in Mechanical Engineering. 2023\\n–HPCL Interview Qualified for HPCL written exam and group task also. 2023\\n–MHRD Scholarship Received State Government Merit Scholarship for Under Graduate 2015-2019',\n",
        "         'generated_questions': \"1.  Your AARIA project involves building a research agent utilizing RAG pipelines and agentic frameworks like LangGraph and CrewAI, interacting with LLMs via APIs like Cohere. Could you elaborate on your experience working with these models, specifically how you approached designing the interactions or 'prompts' within the agentic architecture to guide the model's behavior and achieve the desired research outcomes?\\n2.  The role emphasizes experience with HuggingFace libraries for model fine-tuning and cloud platforms like AWS SageMaker for training and deployment. While these aren't explicitly listed in your technical skills or projects, could you share any exposure you've had to these technologies or similar tools? How would you approach quickly becoming proficient in these areas during the internship?\\n3.  Your Historical Manuscript Restoration project involved training a Vision Transformer model for noise reduction and text enhancement. Could you walk us through your process for training (or fine-tuning, if applicable) this model and the key challenges you faced, particularly regarding data preparation and achieving evaluation metrics like PSNR? Following successful training, what are your thoughts or experience regarding the practical steps and considerations needed to deploy such a model for real-world use?\\n4.  Your background includes an M.Tech in AI from a research institute and projects that demonstrate a strong grasp of AI/ML concepts. The job requires translating cutting-edge AI research into scalable solutions and deploying models in real-world applications. How do you see your research-oriented approach complementing the engineering aspects of this role, and what are the key differences or challenges you anticipate when moving from a research project to building a production-ready system?\"},\n",
        "        {'jd_txt': '\\nJob Title: AI/ML Engineer Intern\\n\\nLocation: Bengaluru, India\\n\\nDuartion : 6 Months\\n\\nCompany Overview: IAI Solution is at the forefront of artificial intelligence and machine learning innovation, driving breakthroughs that impact industries worldwide. We are seeking an experienced AI/ML Engineer intern who is deeply knowledgeable in AI and machine learning techniques, and who thrives in a fast-paced, research-driven environment. If you are passionate about AI, have hands-on experience with model fine-tuning and prompt engineering, and want to be part of a team pushing the boundaries of technology, we would love to hear from you.\\n\\nPosition Summary: We are looking for an AI/ML Engineer intern with a strong background in Python, Django, and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, model fine-tuning, and using the HuggingFace libraries. Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications.\\n\\nKey Responsibilities:\\n\\nDevelop, fine-tune, and deploy machine learning models using Python and Django frameworks.\\nApply prompt engineering techniques to optimize model outputs and improve accuracy.\\nUtilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models.\\nWork on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently.\\nCollaborate with research teams to translate cutting-edge AI research into scalable solutions.\\nImplement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions.\\nStay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects.\\nDocument and share findings, best practices, and solutions across the engineering team.\\nQualifications:\\n\\nStrong proficiency in Python and Django.\\nExperience in prompt engineering and fine-tuning AI models.\\nExtensive experience with HuggingFace libraries and similar AI/ML tools.\\nHands-on experience with cloud platforms such as AWS SageMaker for training and deploying models.\\nBackground in AI/ML research, with a preference for candidates from research institutes.\\nDemonstrated experience in training and deploying machine learning models in real-world applications.\\nSolid understanding of object-oriented programming and problem-solving skills.\\nStrong analytical skills and the ability to work independently or in a team environment.\\nExcellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders.\\nPreferred Qualifications:\\n\\nPrevious experience in academic or industrial research, with published work in AI/ML.\\nProven track record of successful AI model deployments and optimizations.\\nPerks & Benefits:\\n\\nWork on groundbreaking AI/ML projects in a collaborative and innovative environment.\\nAccess to state-of-the-art tools and cloud platforms.\\nOpportunities for professional development and continuous learning.\\nComprehensive health and wellness benefits.\\n\\n',\n",
        "         'filename': 'BALUSA GNANESH_AIML Intern.pdf',\n",
        "         'resume_txt': ' \\n \\n \\n \\n \\nEDUCATION  GNANESH  BALUSA  \\ngnaneshbalusa016g@gmail.com  |LinkedIn/gnaneshbalusa  | +91 7989131105 \\ngithub.com/gnanesh -16 | Medium/gnaneshbalusa  \\nKoneru  Lakshmaiah  University  Graduation:  May 2025 \\nB-Tech ( Honors)  Electronics  and Communication Engineering  GPA:  8.91 \\n \\n PROFESSIONAL  EXPERIENCE  \\nTihan  IIT Hyderabad  Sangareddy,  (On-site) \\nResearch  Ai Software  Engineer  Intern  July2024  – Dec 2024  \\n• Created  a GUI application  using  Qt to analyze  and modify  GPU  packet  streams  from  the Nvidia  AGX  Orin \\ncontroller  on Linux,  enabling  browser -based  usage  and visualization  for autonomous  vehicle  applications.  \\n• Developed a full-stack  web application with React.js and FastAPI , enabling real -time analysis of GPU packet  \\nstreams  from  Nvidia  AGX  Orin.  I gained  2 years  of experience  developing  web applications , by \\nunderstanding of software development process  while working alongside with M.Tech professionals  \\n• Led cloud  migration  projects  to AWS,  ensuring  smooth  transitions  and optimized  cloud  infrastructure.  \\nand Implemented  Agile  methodologies  to streamline  development  workflows  and enhance  team  \\ncollaboration  \\nPROJECTS  \\nAi-Powered  Automated  Testing  for LLMs  – LLM  Test Automation Suite  (Ongoing  Proje ct) Aziznagar,  HY \\nInterview  Project  January - March  2025  \\n• Engineered  Ai-driven  automated  testing  framework  by Building  a Playwright/PyTest -based  solution  to evaluate \\nLLM behavior, response quality, and accuracy through automated test cases, scenario -driven tests, and \\nperformance metrics (accuracy, precision, recall ) \\n• Deployed sentiment and bias detection on Streamlit cloud and Hugging face using ML classifiers; ensured multi -\\nturn response consistency. Integrated REST/SOAP APIs and handled responses via JSON for logging and \\nreplay.  live working video    \\n• Created  an AI agent  for web searches, task scheduling,  and email  updates  using  Groq  Agno,  DuckDuckGo , \\nFirewall , and Email Tools , while automating nightly test executions with GitHub Actions and Docker.  \\n \\nSpeech  Emotion Recognition  – TimnetO1  (Research, IEEE  Conference)  Gujarat,  India  \\nResearch  Project  August  2024  – November . \\n• Designed  an AI/ML driven  Speech  Emotion  Recognition  (SER)  system  using  TIMNET,  achieving  95%  \\naccuracy in noiseless conditions  \\n• Automated  testing  pipelines  for AI model  evaluation , optimizing  hyperparameters  for real-time speech  analysis.  \\n• Ensured  robustness  with threat  protection mechanisms  to secure  AI-driven  SER data. \\nCloud  Uploader  CLI tool Aziznagar,  HY \\nBackend Developer  April  2023  \\n• Developed  a CLI tool that automates  AWS  SDK  authentication , bucket  selection  or creation,  and file transfers  to AWS \\nS3 general -purpose buckets, simplifying the overall upload process  \\n• Integrated  real-time progress  tracking  and enabled  parallel  uploads  for faster  file transfers,  while  incorporating \\nrobust error handling and logging to facilitate easier debugging  \\n• Cloud  Uploader  is a command -line interface  (CLI)  tool designed  to simplify  uploading  files to AWS  S3 General \\npurpose  buckets.  It automates  the process  of authentication  and file transfer  to buckets.  | GitHub  | Project  | Blog  | \\n \\nCERTIFICATIONS  \\n• AWS Certified Cloud Practitioner  – Amazon Web Services                                                               Issued: Nov 2024                  \\n• Git version  Control                          – GitHub Foundations                                                                     Issued: Feb 2025 \\nSKILLS  \\nLanguage  & Databases : Python  | Redis  | SQL Server  Management  Studio  \\nAI & Machine  Learning  NLP | LLMs  (GPT,  OpenAI),  Groq,  Anthropic,  Agno  (Framework)  \\nAutomation  & Testing : Playwright  | PyTest,  AI Test Frameworks  | Git | GitHub  | Gitlab | CI/CD  | Docker  | Kubernetes  | Jenkins  RESEARCH PUBLICATION  \\n \\n• “Evaluating  Gesture  based  Text Generator  Gloves  System  on Arduino  Platform” \\n• “Comparative  Analysis  of Different  Operational  Logic  Gates  for Cutting -Edge  Technology”  \\n• “Analysis  of TIMNET  Emotional  Modelling  Approach  in Noisy  Environment”  \\n \\nACHIVEMENTS  AND  AWARDS  \\n• Developed  Canvect , a Python  package  for CAN  communication  in autonomous vehicles , with 7.2K+  downloads  \\nand 200+  current  views  (PyPI  | GitHub ). \\n• Finalist , NXP  Hackathon  – Ranked  in the top 5% among  1,500+  teams  in a regional  competition  for innovative \\nAI-driven solutions.  \\n• Tata Imagination  Challenge  – Developed  non-verbal  communication  solutions , showcasing  creativity  and \\nproblem -solving skills.  \\n• Best Research  Paper  Award – Recognized  for AI & Machine  Learning -based  TIMNET  Modelling , awarded  a \\nprize of ₹10,000 .  ',\n",
        "         'generated_questions': '1.  Your resume highlights experience with deploying models on platforms like Streamlit/Hugging Face and extensive AWS experience (migration, S3 CLI, certification). Can you elaborate on a project where you deployed an AI/ML model to a cloud environment? Please describe the specific AWS or other cloud services you used for training and deployment, how you utilized Hugging Face libraries in the process, and the key technical challenges you faced during deployment.\\n\\n2.  The role requires experience in prompt engineering and model fine-tuning. Your LLM Test Automation Suite project involves evaluating LLM behavior and response quality. How did you approach designing tests and analyzing LLM outputs in this project, and did this involve any specific techniques related to prompt engineering or understanding how prompts influence model responses? Can you also describe any direct experience you have with fine-tuning pre-trained models, including the objective and process?\\n\\n3.  The job emphasizes translating cutting-edge AI research into scalable solutions. Your Speech Emotion Recognition (SER) project is listed as research aimed for an IEEE Conference. How would you approach taking a model developed in a research context, like your SER system, and preparing it for a production environment? What steps would you take to ensure its robustness, scalability, and efficient deployment for real-time analysis?\\n\\n4.  The job description requires proficiency in Python and Django, along with solid Object-Oriented Programming (OOP) skills. While your resume shows strong Python and backend experience with FastAPI, can you describe your experience specifically with the Django framework? If your direct Django experience is limited, how would you leverage your existing backend development skills and OOP principles to quickly contribute effectively to a Django-based AI project?'},\n",
        "        {'jd_txt': '\\nJob Title: AI/ML Engineer Intern\\n\\nLocation: Bengaluru, India\\n\\nDuartion : 6 Months\\n\\nCompany Overview: IAI Solution is at the forefront of artificial intelligence and machine learning innovation, driving breakthroughs that impact industries worldwide. We are seeking an experienced AI/ML Engineer intern who is deeply knowledgeable in AI and machine learning techniques, and who thrives in a fast-paced, research-driven environment. If you are passionate about AI, have hands-on experience with model fine-tuning and prompt engineering, and want to be part of a team pushing the boundaries of technology, we would love to hear from you.\\n\\nPosition Summary: We are looking for an AI/ML Engineer intern with a strong background in Python, Django, and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, model fine-tuning, and using the HuggingFace libraries. Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications.\\n\\nKey Responsibilities:\\n\\nDevelop, fine-tune, and deploy machine learning models using Python and Django frameworks.\\nApply prompt engineering techniques to optimize model outputs and improve accuracy.\\nUtilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models.\\nWork on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently.\\nCollaborate with research teams to translate cutting-edge AI research into scalable solutions.\\nImplement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions.\\nStay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects.\\nDocument and share findings, best practices, and solutions across the engineering team.\\nQualifications:\\n\\nStrong proficiency in Python and Django.\\nExperience in prompt engineering and fine-tuning AI models.\\nExtensive experience with HuggingFace libraries and similar AI/ML tools.\\nHands-on experience with cloud platforms such as AWS SageMaker for training and deploying models.\\nBackground in AI/ML research, with a preference for candidates from research institutes.\\nDemonstrated experience in training and deploying machine learning models in real-world applications.\\nSolid understanding of object-oriented programming and problem-solving skills.\\nStrong analytical skills and the ability to work independently or in a team environment.\\nExcellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders.\\nPreferred Qualifications:\\n\\nPrevious experience in academic or industrial research, with published work in AI/ML.\\nProven track record of successful AI model deployments and optimizations.\\nPerks & Benefits:\\n\\nWork on groundbreaking AI/ML projects in a collaborative and innovative environment.\\nAccess to state-of-the-art tools and cloud platforms.\\nOpportunities for professional development and continuous learning.\\nComprehensive health and wellness benefits.\\n\\n',\n",
        "         'filename': 'Pawan Kumar_AIML Engineer.pdf',\n",
        "         'resume_txt': 'PAWAN KUMAR UIKEY\\nSeoni, Madhyapradesh ,PinCode- 480887\\n♂phone7587943654 /envel⌢pepawanuikey690@gmail.com /linkedinLinkedin /githubGithub\\nEDUCATION\\nNational Institute of Technology, Raipur Raipur, Chhattisgarh\\nMaster of Computer Applications (MCA) Aug 2022 – 2025\\nGovernment Holkar Science College Indore, Madhya Pradesh\\nBachelor of Computer Science (Bsc) Aug 2019 –Aug 2022\\nTECHNICAL SKILLS\\nLanguages :Python, C++, Javascript, SQL,\\nLibraries :Pandas, Numpy , Matplotlib ,Keras ,TensorFlow , Seaborn ,Sckit-learn, NLTK, SpaCy,TextBlob\\nDatabases : MySQL.\\nDev Tools :ML-Flow ,DVC ,Docker, Git, GitHub, Postman, Jupyter.\\nCourseWork :Machine Learning, OOPS, DBMS, Operating Systems, Computer Network , DSA.\\nEXPERIENCE\\nArtificial Intelligence Engineer Internship TECHNOCOLABS SOFTWARE March 2025 - Present\\n•Worked on the ETA Prediction Project forLast Mile Delivery Optimization , focusing on Phase 1: Data\\nPreparation .\\n•Collected, explored, and preprocessed datasets to ensure data quality andreliability for further analysis and model\\ndevelopment.\\n•Performed exploratory data analysis (EDA) ,data cleaning , and feature engineering to optimize model input.\\nRESEARCH PAPER\\nPredicting Rose Leaf Diseases Using Deep Learning Models DEEPLEARNING ,CNN, RESNET50 IEEE (Publication Pending)\\n•Accepted for publication in the 2025 International Conference on Ambient Intelligence in Health Care (ICAIHC) ,\\nwith IEEE publication pending.\\n•Co-authored by Naeem Ahmad, Himanshu Tiwari, and Pawan Uikey .\\n•Implemented a deep learning-based approach for accurate classification of rose leaf diseases, leveraging pre-trained\\nmodels and custom architectures to enhance accuracy.\\n•DOI/Link: Available upon publication.\\nPROJECTS\\nRose Leaf Disease Detection PYTHON ,TENSOR FLOW,KERAS ,CNN ,RESNET50 GitHub\\n•Designed a deep learning model based on ResNet50 and custom layers, achieving over 98% accuracy in identifying\\n’Black Spot’, ’Downy Mildew’, and ’Fresh Leaf’ diseases in rose leaves.\\n•Implemented data augmentation techniques such as rotation and flipping to enhance the model’s robustness, ensuring\\nsuperior generalization and performance on unseen images.\\n•Built an interactive Streamlit web app enabling real-time prediction of rose leaf diseases with image upload, instant\\nclassification results, and confidence scores.\\nNews Sentiment Analysis &Text-to-Speech PYTHON ,BEAUTIFUL SOUP,NLP GitHub\\n•Developed a web-based system to extract, analyze, and summarize news articles related to a given company using\\nBeautifulSoup for web scraping.\\n•Performed sentiment analysis on extracted articles and conducted a comparative study to assess variations in media\\ncoverage.\\n•Implemented text-to-speech (TTS) conversion in Hindi for summarized content using an open-source TTS model.\\nACHIEVEMENTS\\n•Solved 100+ problems on Data Structures and Algorithms across various coding platforms.\\n• Achieved 4-star rating in Python programming on HackerRank.\\nCODING PLATFORM\\nLeetcode |CodeChef |GFG |',\n",
        "         'generated_questions': \"Your research and projects, particularly the Rose Leaf Disease Detection, involve leveraging deep learning models. Can you elaborate on your experience working with pre-trained models like ResNet50? How did you adapt or fine-tune these models for your specific task, and what considerations did you take into account regarding data augmentation, model architecture, and evaluation metrics?\\n\\nThe role requires experience with prompt engineering and utilizing HuggingFace libraries for state-of-the-art models. While your resume details traditional NLP skills, can you discuss any exposure you've had to transformer models, prompt engineering techniques, or working with libraries like HuggingFace? If your direct experience is limited, how would you approach quickly gaining proficiency in these areas?\\n\\nDeploying models in a scalable environment is crucial, often involving cloud platforms like AWS SageMaker. Your resume lists tools like Docker, ML-Flow, and DVC. Can you describe how you would use these or other tools in conjunction with a cloud platform to train, deploy, and manage the lifecycle of a machine learning model in a production-like setting?\\n\\nIAI Solution operates in a research-driven environment. Based on your experience with your published research paper and projects, how do you stay updated with the latest advancements in AI/ML, and how would you approach translating cutting-edge research concepts into practical, implementable solutions for specific problems?\"},\n",
        "        {'jd_txt': '\\nJob Title: AI/ML Engineer Intern\\n\\nLocation: Bengaluru, India\\n\\nDuartion : 6 Months\\n\\nCompany Overview: IAI Solution is at the forefront of artificial intelligence and machine learning innovation, driving breakthroughs that impact industries worldwide. We are seeking an experienced AI/ML Engineer intern who is deeply knowledgeable in AI and machine learning techniques, and who thrives in a fast-paced, research-driven environment. If you are passionate about AI, have hands-on experience with model fine-tuning and prompt engineering, and want to be part of a team pushing the boundaries of technology, we would love to hear from you.\\n\\nPosition Summary: We are looking for an AI/ML Engineer intern with a strong background in Python, Django, and Object-Oriented Programming (OOP). The ideal candidate should have significant experience in prompt engineering, model fine-tuning, and using the HuggingFace libraries. Additionally, expertise in working with cloud platforms such as AWS SageMaker or similar services for training AI models is essential. Priority will be given to candidates with a research background, particularly those who have successfully fine-tuned and deployed AI models in real-world applications.\\n\\nKey Responsibilities:\\n\\nDevelop, fine-tune, and deploy machine learning models using Python and Django frameworks.\\nApply prompt engineering techniques to optimize model outputs and improve accuracy.\\nUtilize HuggingFace libraries and other ML tools to build and fine-tune state-of-the-art models.\\nWork on cloud platforms like AWS SageMaker or equivalent to train and deploy AI models efficiently.\\nCollaborate with research teams to translate cutting-edge AI research into scalable solutions.\\nImplement object-oriented programming (OOP) principles and problem-solving strategies in developing AI solutions.\\nStay updated with the latest advancements in AI/ML and integrate new techniques into ongoing projects.\\nDocument and share findings, best practices, and solutions across the engineering team.\\nQualifications:\\n\\nStrong proficiency in Python and Django.\\nExperience in prompt engineering and fine-tuning AI models.\\nExtensive experience with HuggingFace libraries and similar AI/ML tools.\\nHands-on experience with cloud platforms such as AWS SageMaker for training and deploying models.\\nBackground in AI/ML research, with a preference for candidates from research institutes.\\nDemonstrated experience in training and deploying machine learning models in real-world applications.\\nSolid understanding of object-oriented programming and problem-solving skills.\\nStrong analytical skills and the ability to work independently or in a team environment.\\nExcellent communication skills, with the ability to present complex technical concepts to non-technical stakeholders.\\nPreferred Qualifications:\\n\\nPrevious experience in academic or industrial research, with published work in AI/ML.\\nProven track record of successful AI model deployments and optimizations.\\nPerks & Benefits:\\n\\nWork on groundbreaking AI/ML projects in a collaborative and innovative environment.\\nAccess to state-of-the-art tools and cloud platforms.\\nOpportunities for professional development and continuous learning.\\nComprehensive health and wellness benefits.\\n\\n',\n",
        "         'filename': 'Shubham Murtadak_AIML Engineer.pdf',\n",
        "         'resume_txt': 'SHUBHAM MURTADAK\\nAI Engineer\\n/ne+91-9322191338 shubhammurtadak022@gmail.com /♀nednlinkedin /gtbgithub\\nABOUT ME\\nI am an AI Engineer proficient in Python, Machine Learning, Deep Learning, NLP, and Generative AI, passionate\\nabout creating impactful solutions. Driven by curiosity and an unwavering desire to learn, I am committed to\\ncontinuous growth and making meaningful contributions in the field of AI. You can check my work, proof of my latest\\nproject: DocEase.in.\\nEDUCATION\\nB.E. in Artificial Intelligence & Data Science 2021-2025\\nPES Modern College of Engineering Pune\\nCGPA: 9.20\\nSenior Secondary (XII), Science 2020\\nShree Ganesh Jr College, HSC Board\\nGrades: 83.38%\\nSecondary (X) 2018\\nNew English School Korhale, India\\nGrades: 89%\\nSKILLS\\nPrimary Skills:\\n•Programming Languages: Python, R, C++, SQL\\n•Python/ML/CV Packages: Pandas,Numpy, Matplotlib, Seaborn,Scikit-Learn\\n•Knowledge of Machine Learning\\n•Deep Learning: Neural Network,ANN,CNN,Transfer Learning\\n•TensorFlow\\n•NLP : NLTK,Spacy,RNN,LSTM RNN, Transformers\\n•Generative AI :LLM,RAG, LLM Finetuning\\n•LangChain Framework,LlamaIndex Framework,Vector Databases,Graph Databases\\n•Agentic AI , Autogen Framework, Crewai Framework ,Langgraph\\nSecondary Skills:\\n•WEB TECHNOLOGIES: Basics of HTML, CSS, JavaScript,React,Flask,Fastapi,Streamlit\\n•DATABASES: MySQL, MongoDB\\n•Visualization Tools: PowerBI, Microsoft Excel\\n•Web Scraping: Scrapy, BeautifulSoup, Selenium\\n•Cloud Platform Services: AWS\\n•Docker\\nEXPERIENCEGenerative AI Intern Jan 2025 - Present\\nStealth Startup Bengaluru, Karnataka, India (Remote)\\n•Developed a Proof of Concept (PoC) for a SaaS-based chatbot, enabling clients to generate unique URLs\\nand JavaScript snippets for seamless integration into their platforms, while storing conversation history in\\nmongodb and deploying using AWS EC2 instance with Docker. Deployed Link.\\n•Developed an AI-powered automatic email response system using ai agents for healthcare, integrating Mon-\\ngoDB for internal data retrieval and external healthcare sources for accurate responses. Used AI agents to\\nanalyze incoming emails, generate response ,calculate confidence scores, preventing responses below 60% con-\\nfidence from being sent. Built a React-based dashboard for reviewing and editing low-confidence emails and\\nsent them,added a scheduling feature to start/stop automated responses.\\n•Developed a job portal for an EdTech platform that scrapes job listings from top IT companies, automatically\\nupdating the database every day to add newly posted job opportunities, ensuring that users always have\\naccess to the latest openings in the industry.\\nData Science Intern June 2024 - jan 2024\\nDataNnoviteSol LLP Pune, Maharashtra (Onsite)\\n•Conducted research and development to identify the best tools and solutions for project requirements, ensuring\\noptimal fit for various use cases.\\n•Developed a comprehensive solution for analyzing and processing clients’ transaction and campaign data,\\nincorporating Generative AI to optimize campaign performance.\\n•Develop Generative AI module for dataRobo , DataNnovite’s AI-driven platform, allowing users to query and\\nretrieve document content via a conversational interface.\\nPROJECTS\\n1. Automated Business Insights and Campaign Optimization\\n•Developed an LLM-powered solution using RAG to analyze client transaction and campaign data, enabling\\ndata-driven decision-making through a custom dashboard.\\n•Generated personalized texts messages to Targeted specific customer segments for future campaigns.\\n•Segmented customers using customer lifetime value (CLV).\\n•Containerized the entire application using Docker, simplifying deployment, ensuring consistency across envi-\\nronments, and enhancing scalability.\\n•Tech Stack: Python |LangChain |RAG |Milvus |Time Series Analysis |Flask |Docker\\n2. DataRobo\\n•Developed a question-answering module for structured and unstructured documents (KYC forms, PAN, in-\\nvoices, legal contracts).\\n•Fine-tuned LLMs ( Gemma2 2B ,Qwen-2.5 3B ) for use-case optimizations.\\n•Enabled multi-document and Multimodal RAG querying, integrating text and images from PDFs.\\n•Managed multi-user chat history with MongoDB for context-aware responses.\\n•Optimized extraction and querying for large PDFs (up to 100 pages).\\n•Tech Stack: Python |LangChain |RAG |Milvus |Gemini 1.5-Pro |Gemini 1.5-Flash |LlamaParser |Flask\\n|MongoDB\\n3. Anuwad click here•Developed an AI-powered translation platform enabling speech-to-text ,language translation , and text-\\nto-speech functionalities.\\n•Built a robust module supporting multiple Indian languages (Hindi, Kannada, Marathi, etc.), ensuring\\naccurate recognition of diverse accents and dialects.\\n•Integrated IndicTrans2 models for precise language translations with fallback mechanisms for unsupported\\nlanguages.\\n•Implemented bidirectional communication , allowing seamless interaction between mentor and user lan-\\nguages with a toggle feature.\\n•Designed an intuitive React.js-based UI optimized for accessibility with visual cues for real-time trans-\\nlation and speech status.\\n•Managed user authentication via Firebase , ensuring secure and role-based access.\\n•Tech Stack: Python |Flask |gTTS |React |Firebase |pyaudio\\n4. POExtractor click here\\n•Developed an AI tool for real-time email monitoring and automated purchase order (PO) classification.\\n•Parsed key PO details (PO number, items, quantities, delivery dates, payment terms) using MiStral-8x7B\\nandLLAMA Parser .\\n•Built a user-friendly interface with FastAPI (backend) and React (frontend) for data visualization and manual\\ncorrections.\\n•User can edit and send replies to classifed purchase orders mails on React dashboard.\\n•Enabled multi-format attachment processing (PDF, Excel, CSV, Images, Word).\\n•Tech Stack: Python |LLAMA Parser |LangChain |FastAPI |React\\n5. Anuwad - English to Marathi Translator click here\\n•Developed a neural machine translation model using TensorFlow , leveraging the Bahdanau Attention mech-\\nanism to translate sentences from English to Marathi.\\n•Implemented an encoder-decoder architecture, where the encoder processes input sequences and the decoder\\ngenerates target sequences based on context.\\n•Integrated Bahdanau Attention to improve translation quality by enabling the decoder to focus on relevant\\nparts of the input sequence during generation.\\n•Built a user-friendly UI using Flask , allowing users to input English text and receive Marathi translations\\nseamlessly.\\n•Tech Stack: Python |TensorFlow |Bahdanau Attention |Flask\\n6. D-predicto click here\\n•Developed an end-to-end application predicting diabetes ,heart disease , and Parkinson’s disease using\\nXGBoost model.\\n•Integrated an Genai based chatbot into the website to improve user interaction and access to information.\\n•Included a feature for users to book appointments with doctors if needed.\\n•Tech Stack: Python |SK Learn |ML |Numpy |Pandas |NLP |Flask |Langchain |GitHub\\n7. RetainIQ click here\\n•Developed a system for predicting employee churn using RandomForest model to analyze workforce data.•Implemented features for model training, batch prediction, and single employee prediction to determine re-\\ntention likelihood.\\n•Built using Flask for web-based interaction\\n•Tech Stack: Python |SK Learn |ML |Numpy |Pandas |NLP |Flask |GitHub\\nCERTIFICATES\\n•LLM MOOC 2024 by universtiy of Berkeley\\n•Langchain with python bootcamp Udemy\\n•tensorflow for deep learning Udemy\\nACHIEVEMENTS\\n•Winners Of Prostart 2023(Software Category)-Team Matrix\\n•Earned Golden Badge in Python On HackerRank',\n",
        "         'generated_questions': \"1.  Your resume highlights experience fine-tuning LLMs like Gemma2 and Qwen-2.5 and deploying AI solutions. Can you walk us through the process of fine-tuning one of these models for a specific use case you worked on? Include details on data preparation, the fine-tuning approach you chose, how you evaluated the results, and the challenges you encountered during the process.\\n\\n2.  The job requires experience with HuggingFace libraries and prompt engineering. While your projects mention using various LLMs and RAG, can you elaborate on your specific experience using HuggingFace libraries (e.g., `transformers`, `PEFT`) for model interaction or fine-tuning? Additionally, how did you apply prompt engineering techniques to optimize the output or performance of the LLMs in your projects?\\n\\n3.  You've mentioned deploying projects using Docker and AWS EC2 instances. The role requires experience with cloud platforms like AWS SageMaker for training and deploying models efficiently. Can you describe your experience deploying machine learning models to production? While SageMaker is preferred, have you used other cloud services or strategies for managing the training lifecycle and scaling of models?\\n\\n4.  The job description emphasizes a research background and deploying models in real-world applications. Can you describe a time in your projects or internships where you had to research and evaluate different AI/ML models or approaches to solve a specific problem? How did you make your decision, and what was the outcome? This helps us understand your research process and ability to translate research into practical solutions.\"}\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfVHOhvnYdxl",
        "outputId": "0500c0b6-3431-4529-be0e-392e232a69fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.  The job description emphasizes proficiency in Django and experience with cloud platforms like AWS SageMaker for training and deploying models. Based on your background, which includes Python and FastAPI experience but doesn't explicitly mention Django or cloud MLOps platforms, how would you approach quickly gaining proficiency in these areas to meet the demands of this role?\n",
            "2.  Your resume highlights skills in Fine Tuning, Prompt Engineering (RAG), and using HuggingFace libraries. Could you describe a specific instance where you applied fine-tuning or advanced prompt engineering techniques to improve the performance or behavior of a language model or other AI model? Please elaborate on the problem, your approach using these tools, and the outcome.\n",
            "3.  The role requires deploying AI models in real-world applications and potentially collaborating with research teams. Drawing from your project experience, like the RAG application or the Multi-Agent system, how did you consider factors like scalability, reliability, or integration for potential deployment? How do you typically approach translating theoretical AI concepts or research findings into practical, working code?\n",
            "4.  The job description mentions the importance of Object-Oriented Programming (OOP) and problem-solving skills. Can you provide an example from one of your projects, perhaps the Multi-Agent System or the RAG application, where you applied OOP principles to structure your code and solve a specific technical challenge?\n"
          ]
        }
      ],
      "source": [
        "print(data[0]['generated_questions'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3rsRU51xtzP",
        "outputId": "5b896670-f7c7-418c-d0e5-a284afbc702d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 1.24.3\n",
            "Uninstalling numpy-1.24.3:\n",
            "  Successfully uninstalled numpy-1.24.3\n",
            "Found existing installation: scipy 1.10.1\n",
            "Uninstalling scipy-1.10.1:\n",
            "  Successfully uninstalled scipy-1.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y numpy scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRbL7jUDxu7V",
        "outputId": "dcc31e14-8772-4e8f-c1c1-96a349b4b719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "cTp_GIcP8GyC",
        "outputId": "5b5bd625-0169-4d1d-a9ca-13cd5b490987"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy.rec'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5be8ac0dbd2e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Get device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/TTS/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_configs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseDatasetConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxtts_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXttsConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxtts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXttsArgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXttsAudioConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradam\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/TTS/tts/configs/xtts_config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared_configs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseTTSConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxtts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXttsArgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXttsAudioConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/TTS/tts/models/xtts.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_fsspec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhifigan_decoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHifiDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_generator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_stream_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/TTS/tts/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/TTS/tts/layers/losses.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msequence_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSSIMLoss\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_SSIMLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mTTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_transforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTorchSTFT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/TTS/tts/utils/helpers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbetabinom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    622\u001b[0m from ._warnings_errors import (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    623\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 624\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_stats_py\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_variation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistance_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_importlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'scipy.{name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m from ._sputils import (asmatrix, check_reshape_kwargs, check_shape,\n\u001b[0m\u001b[1;32m      6\u001b[0m                        \u001b[0mget_sum_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misdense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                        matrix, validateaxis, getdtype)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_sputils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_ulong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_namespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_docscrape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctionDoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/_array_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_api_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from scipy._lib.array_api_compat import (\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mis_array_api_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxp_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/array_api_compat/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# from numpy import * doesn't overwrite these builtin names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.rec'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from TTS.api import TTS\n",
        "\n",
        "# Get device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# List available 🐸TTS models\n",
        "print(TTS().list_models())\n",
        "\n",
        "# Initialize TTS\n",
        "tts = TTS(\"tts_models/de/thorsten/tacotron2-DDC\").to(device)\n",
        "\n",
        "# List speakers\n",
        "print(tts.speakers)\n",
        "\n",
        "# TTS to a file, use a preset speaker\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkxAxJ4uwT_r"
      },
      "outputs": [],
      "source": [
        "tts.tts_to_file(\n",
        "  text=\" The job description emphasizes proficiency in Django and experience with cloud platforms like AWS SageMaker for training and deploying models. Based on your background, which includes Python and FastAPI experience but doesn't explicitly mention Django or cloud MLOps platforms, how would you approach quickly gaining proficiency in these areas to meet the demands of this role?\",\n",
        "  file_path=\"output.wav\"\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
